{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "se9t7Ikhr7tG"
   },
   "source": [
    "# 1. Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HaPqj6Y4rZSW"
   },
   "outputs": [],
   "source": [
    "!pip install -U -q PyDrive\n",
    "from pydrive.auth import GoogleAuth\n",
    "from pydrive.drive import GoogleDrive\n",
    "from google.colab import auth\n",
    "from oauth2client.client import GoogleCredentials\n",
    "# Authenticate and create the PyDrive client.\n",
    "auth.authenticate_user()\n",
    "gauth = GoogleAuth()\n",
    "gauth.credentials = GoogleCredentials.get_application_default()\n",
    "drive = GoogleDrive(gauth)\n",
    "\n",
    "id_trian = '1ukOHzF-Rpi8_Ig4a40j_tlxscaGvyoHD'\n",
    "id_val = '1VwEmbqMZznZcuGeXOksXgiIrQ9VUC2dg'\n",
    "id_test = '17zD8SLoNL7EANiEneNzxB4L4kjqFMUg_'\n",
    "\n",
    "downloaded = drive.CreateFile({'id':id_trian}) \n",
    "downloaded.GetContentFile('train.csv')\n",
    "\n",
    "downloaded = drive.CreateFile({'id':id_val}) \n",
    "downloaded.GetContentFile('val.csv')\n",
    "\n",
    "downloaded = drive.CreateFile({'id':id_test}) \n",
    "downloaded.GetContentFile('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "a2_h6xmJr5W0"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# read train\n",
    "df_train = pd.read_csv(\"train.csv\")\n",
    "train_sent = [i.split() for i in list(df_train.Sentence)]\n",
    "train_NER = [i.split() for i in list(df_train.NER)]\n",
    "\n",
    "# read val and add them after train\n",
    "df_val = pd.read_csv(\"val.csv\")\n",
    "train_sent += [i.split() for i in list(df_val.Sentence)]\n",
    "train_NER += [i.split() for i in list(df_val.NER)]\n",
    "\n",
    "# read test\n",
    "df_test = pd.read_csv(\"test.csv\")\n",
    "test_sent = [i.split() for i in list(df_test.Sentence)]\n",
    "\n",
    "# all sentence for processing\n",
    "all_sentence = train_sent + test_sent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Test lemmatisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/ubuntu/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# From Lab05\n",
    "# Lemmatize\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "def lemmatize(x):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    lemma_sentence = [lemmatizer.lemmatize(w) for w in x]\n",
    "\n",
    "    return lemma_sentence\n",
    "\n",
    "\n",
    "all_sentence_lemma = [lemmatize(s) for s in all_sentence]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Test stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From Lab05\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "stemmer = PorterStemmer()\n",
    "# Transform data lists into tokens\n",
    "# Stem the words\n",
    "def word_stemmer(lists, isSentence):\n",
    "    tokens = []\n",
    "\n",
    "    for unstemmed_tokens in lists:\n",
    "        temp = []\n",
    "        for unstemmed_token in unstemmed_tokens:\n",
    "            unstemmed_token = stemmer.stem(unstemmed_token)\n",
    "            temp.append(unstemmed_token)\n",
    "        tokens.append(temp)\n",
    "\n",
    "    return tokens\n",
    "\n",
    "all_sentence_stem = word_stemmer(all_sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UoxBItydthZZ"
   },
   "source": [
    "# 4. Feature Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ItfOwzvftnnb"
   },
   "source": [
    "## 4.1 Word Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "s6bEEVrovD13"
   },
   "outputs": [],
   "source": [
    "## word dic\n",
    "word_list = []\n",
    "for sentence in all_sentence:\n",
    "  word_list.extend(sentence)\n",
    "unique_word = list(set(word_list))\n",
    "\n",
    "ix_2_word = {ix: word for ix, word in enumerate(unique_word)}\n",
    "word_2_ix = {word: ix for ix, word in ix_2_word.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "id": "MTm2rWrOsIvk",
    "outputId": "4dc998ca-d67b-40d7-d165-14a717c63497"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/erasure/lib/python3.6/site-packages/ipykernel_launcher.py:12: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "  if sys.path[0] == '':\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(13972, 100)"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## From Lab 9\n",
    "import gensim.downloader as api\n",
    "import numpy as np\n",
    "\n",
    "EMBEDDING_DIM = 100\n",
    "## change to 100 dimension word embedding\n",
    "word_emb_model = api.load(\"glove-wiki-gigaword-100\") \n",
    "\n",
    "embedding_matrix = []\n",
    "for ix in range(len(ix_2_word)):\n",
    "    try:\n",
    "        embedding_matrix.append(word_emb_model.wv[ix_2_word[ix]])\n",
    "    except:\n",
    "        embedding_matrix.append([0]*EMBEDDING_DIM)\n",
    "embedding_matrix = np.array(embedding_matrix)\n",
    "embedding_matrix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Lana9nMZ2CIt"
   },
   "source": [
    "## 4.2 Other features - Part of Speech and Parse Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nuhbDid92As7"
   },
   "outputs": [],
   "source": [
    "### From Lab 7\n",
    "import spacy\n",
    "\n",
    "#load the spacy api with the pre-trained statistical models for English. English multi-task CNN trained on OntoNotes\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# add up all the sentence for Pos and Parse Tree\n",
    "all_sentence_string = list(df_train.Sentence) + list(df_val.Sentence) + list(df_test.Sentence)\n",
    "\n",
    "pos = []\n",
    "pt = []\n",
    "for sentence in all_sentence_string:\n",
    "  # print(sentence)\n",
    "  parse = nlp(sentence)\n",
    "  # generate parse tree feature\n",
    "  pt.append([token.dep_ for token in parse][:len(sentence.split(\" \"))])\n",
    "  # generate part of speech feature\n",
    "  pos.append([token.pos_ for token in parse][:len(sentence.split(\" \"))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WOCj8xVr4rVn"
   },
   "outputs": [],
   "source": [
    "def unique(lst):\n",
    "  uniq = []\n",
    "  for i in lst:\n",
    "    uniq.extend(i)\n",
    "  uniq = list(set(uniq))\n",
    "  label_2_ix = {tag: ix for ix, tag in enumerate(uniq)}\n",
    "  return uniq, label_2_ix\n",
    "\n",
    "# for pos and parse tree, because the number of them is short, i decide to use one embedding matrix for them\n",
    "other_feature_unique, other_feature_2_ix = unique(pt + pos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9terafAUDPl3"
   },
   "source": [
    "# 5. Model Definition - Modified Bi-LSTM with CRF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3Sfw3xEMEyRE"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.autograd as autograd\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import f1_score\n",
    "import datetime\n",
    "\n",
    "torch.manual_seed(1)\n",
    "\n",
    "def argmax(vec):\n",
    "    # return the argmax as a python int\n",
    "    _, idx = torch.max(vec, 1)\n",
    "    return idx.item()\n",
    "\n",
    "# Compute log sum exp in a numerically stable way for the forward algorithm\n",
    "def log_sum_exp(vec):\n",
    "    max_score = vec[0, argmax(vec)]\n",
    "    max_score_broadcast = max_score.view(1, -1).expand(1, vec.size()[1])\n",
    "    return max_score + \\\n",
    "        torch.log(torch.sum(torch.exp(vec - max_score_broadcast)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cNS-FDAhDRb3"
   },
   "outputs": [],
   "source": [
    "## Model is modified from lab 9 to achieve different features input and evaluation on different layers and attention methods\n",
    "class BiLSTM_CRF(nn.Module):\n",
    "\n",
    "    def __init__(self, vocab_size, tag_to_ix, embedding_dim, other_feature_dim, hidden_dim, attetion = \"Dot Product\", other_features = [\"pt\",\"pos\"], layers = 1):\n",
    "        super(BiLSTM_CRF, self).__init__()\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.vocab_size = vocab_size\n",
    "        self.tag_to_ix = tag_to_ix\n",
    "        self.tagset_size = len(tag_to_ix)\n",
    "        self.layers = layers\n",
    "        self.other_feature = other_features\n",
    "\n",
    "        self.other_feature_embeds = nn.Embedding(len(other_feature_2_ix), other_feature_dim)\n",
    "\n",
    "        self.attention_method = attetion\n",
    "\n",
    "        self.word_embeds = nn.Embedding(vocab_size, embedding_dim)\n",
    "\n",
    "        \"\"\"Here we use the embedding matrix as the initial weights of nn.Embedding\"\"\"\n",
    "        self.word_embeds.weight.data.copy_(torch.from_numpy(embedding_matrix))\n",
    "\n",
    "        if \"pt\" in other_features:\n",
    "            self.embedding_dim += other_feature_dim\n",
    "        if \"pos\" in other_features:\n",
    "            self.embedding_dim += other_feature_dim\n",
    "        \n",
    "        self.lstm = nn.LSTM(self.embedding_dim, hidden_dim // 2,\n",
    "                            num_layers=layers, bidirectional=True)\n",
    "\n",
    "        # Maps the output of the LSTM into tag space.\n",
    "        if self.attention_method == \"No Attention\":\n",
    "            self.hidden2tag = nn.Linear(hidden_dim, self.tagset_size)\n",
    "        else:\n",
    "            self.hidden2tag = nn.Linear(hidden_dim * 2, self.tagset_size)\n",
    "\n",
    "        # Matrix of transition parameters.  Entry i,j is the score of\n",
    "        # transitioning *to* i *from* j.\n",
    "        self.transitions = nn.Parameter(\n",
    "            torch.randn(self.tagset_size, self.tagset_size))\n",
    "\n",
    "        # These two statements enforce the constraint that we never transfer\n",
    "        # to the start tag and we never transfer from the stop tag\n",
    "        self.transitions.data[tag_to_ix[START_TAG], :] = -10000\n",
    "        self.transitions.data[:, tag_to_ix[STOP_TAG]] = -10000\n",
    "\n",
    "        self.hidden = self.init_hidden()\n",
    "\n",
    "    def init_hidden(self):\n",
    "        return (torch.randn(2 * self.layers, 1, self.hidden_dim // 2).to(device),\n",
    "                torch.randn(2 * self.layers, 1, self.hidden_dim // 2).to(device))\n",
    "\n",
    "    def _forward_alg(self, feats):\n",
    "        # Do the forward algorithm to compute the partition function\n",
    "        init_alphas = torch.full((1, self.tagset_size), -10000.).to(device)\n",
    "        # START_TAG has all of the score.\n",
    "        init_alphas[0][self.tag_to_ix[START_TAG]] = 0.\n",
    "\n",
    "        # Wrap in a variable so that we will get automatic backprop\n",
    "        forward_var = init_alphas\n",
    "\n",
    "        # Iterate through the sentence\n",
    "        for feat in feats:\n",
    "            alphas_t = []  # The forward tensors at this timestep\n",
    "            for next_tag in range(self.tagset_size):\n",
    "                # broadcast the emission score: it is the same regardless of\n",
    "                # the previous tag\n",
    "                emit_score = feat[next_tag].view(\n",
    "                    1, -1).expand(1, self.tagset_size)\n",
    "                # the ith entry of trans_score is the score of transitioning to\n",
    "                # next_tag from i\n",
    "                trans_score = self.transitions[next_tag].view(1, -1)\n",
    "                # The ith entry of next_tag_var is the value for the\n",
    "                # edge (i -> next_tag) before we do log-sum-exp\n",
    "                next_tag_var = forward_var + trans_score + emit_score\n",
    "                # The forward variable for this tag is log-sum-exp of all the\n",
    "                # scores.\n",
    "                alphas_t.append(log_sum_exp(next_tag_var).view(1))\n",
    "            forward_var = torch.cat(alphas_t).view(1, -1)\n",
    "        terminal_var = forward_var + self.transitions[self.tag_to_ix[STOP_TAG]]\n",
    "        alpha = log_sum_exp(terminal_var)\n",
    "        return alpha\n",
    "\n",
    "    def _get_lstm_features(self, sentence, other_features = None):\n",
    "        self.hidden = self.init_hidden()\n",
    "        embeds = self.word_embeds(sentence).view(len(sentence), 1, -1)\n",
    "        \n",
    "        # print(\"before: \", embeds.shape)\n",
    "        ## dictionary based other features\n",
    "        if \"pos\" in self.other_feature:\n",
    "            new = self.other_feature_embeds(other_features[\"pos\"]).view(len(sentence), 1, -1)\n",
    "            # print(other_features[\"pos\"])\n",
    "            # print(sentence)\n",
    "            # print(\"new_pos: \", new.shape)\n",
    "            embeds = torch.cat((embeds, new), dim = -1)\n",
    "        if \"pt\" in self.other_feature:\n",
    "            new = self.other_feature_embeds(other_features[\"pt\"]).view(len(sentence), 1, -1)\n",
    "            # print(\"new_pt: \", new.shape)\n",
    "            embeds = torch.cat((embeds, new), dim = -1)\n",
    "          \n",
    "        # print(embeds.shape)\n",
    "\n",
    "        lstm_out, self.hidden = self.lstm(embeds, self.hidden)\n",
    "        \n",
    "        # for self attention\n",
    "        lstm_out_1 = lstm_out.view(lstm_out.size(1), lstm_out.size(0), lstm_out.size(2))\n",
    "        lstm_out_2 = lstm_out.view(lstm_out.size(1), lstm_out.size(2), lstm_out.size(0))\n",
    "\n",
    "        if self.attention_method == \"Dot Product\":\n",
    "            attn_weights = F.softmax(torch.bmm(lstm_out_1, lstm_out_2),dim=-1)\n",
    "            attn_output = torch.bmm(attn_weights, lstm_out_1)\n",
    "            concat_output = torch.cat((attn_output, lstm_out_1), dim = -1)\n",
    "            lstm_out = concat_output.view(len(sentence), self.hidden_dim * 2)\n",
    "\n",
    "        elif self.attention_method == \"Scale Dot Product\":\n",
    "            attn_weights = F.softmax(1/np.sqrt(self.hidden_dim)*torch.bmm(lstm_out_1, lstm_out_2),dim=-1)\n",
    "            attn_output = torch.bmm(attn_weights, lstm_out_1)\n",
    "            concat_output = torch.cat((attn_output, lstm_out_1), dim = -1)\n",
    "            lstm_out = concat_output.view(len(sentence), self.hidden_dim * 2)\n",
    "        else:\n",
    "            lstm_out = lstm_out.view(len(sentence), self.hidden_dim)\n",
    "            \n",
    "        lstm_feats = self.hidden2tag(lstm_out)\n",
    "        return lstm_feats\n",
    "\n",
    "    def _score_sentence(self, feats, tags):\n",
    "        # Gives the score of a provided tag sequence\n",
    "        score = torch.zeros(1).to(device)\n",
    "        tags = torch.cat([torch.tensor([self.tag_to_ix[START_TAG]], dtype=torch.long).to(device), tags])\n",
    "        for i, feat in enumerate(feats):\n",
    "            score = score + \\\n",
    "                self.transitions[tags[i + 1], tags[i]] + feat[tags[i + 1]]\n",
    "        score = score + self.transitions[self.tag_to_ix[STOP_TAG], tags[-1]]\n",
    "        return score\n",
    "\n",
    "    def _viterbi_decode(self, feats):\n",
    "        backpointers = []\n",
    "\n",
    "        # Initialize the viterbi variables in log space\n",
    "        init_vvars = torch.full((1, self.tagset_size), -10000.).to(device)\n",
    "        init_vvars[0][self.tag_to_ix[START_TAG]] = 0\n",
    "\n",
    "        # forward_var at step i holds the viterbi variables for step i-1\n",
    "        forward_var = init_vvars\n",
    "        for feat in feats:\n",
    "            bptrs_t = []  # holds the backpointers for this step\n",
    "            viterbivars_t = []  # holds the viterbi variables for this step\n",
    "\n",
    "            for next_tag in range(self.tagset_size):\n",
    "                # next_tag_var[i] holds the viterbi variable for tag i at the\n",
    "                # previous step, plus the score of transitioning\n",
    "                # from tag i to next_tag.\n",
    "                # We don't include the emission scores here because the max\n",
    "                # does not depend on them (we add them in below)\n",
    "                next_tag_var = forward_var + self.transitions[next_tag]\n",
    "                best_tag_id = argmax(next_tag_var)\n",
    "                bptrs_t.append(best_tag_id)\n",
    "                viterbivars_t.append(next_tag_var[0][best_tag_id].view(1))\n",
    "            # Now add in the emission scores, and assign forward_var to the set\n",
    "            # of viterbi variables we just computed\n",
    "            forward_var = (torch.cat(viterbivars_t) + feat).view(1, -1)\n",
    "            backpointers.append(bptrs_t)\n",
    "\n",
    "        # Transition to STOP_TAG\n",
    "        terminal_var = forward_var + self.transitions[self.tag_to_ix[STOP_TAG]]\n",
    "        best_tag_id = argmax(terminal_var)\n",
    "        path_score = terminal_var[0][best_tag_id]\n",
    "\n",
    "        # Follow the back pointers to decode the best path.\n",
    "        best_path = [best_tag_id]\n",
    "        for bptrs_t in reversed(backpointers):\n",
    "            best_tag_id = bptrs_t[best_tag_id]\n",
    "            best_path.append(best_tag_id)\n",
    "        # Pop off the start tag (we dont want to return that to the caller)\n",
    "        start = best_path.pop()\n",
    "        assert start == self.tag_to_ix[START_TAG]  # Sanity check\n",
    "        best_path.reverse()\n",
    "        return path_score, best_path\n",
    "\n",
    "    def neg_log_likelihood(self, sentence, tags, other_feature = None):\n",
    "        feats = self._get_lstm_features(sentence, other_feature)\n",
    "        forward_score = self._forward_alg(feats)\n",
    "        gold_score = self._score_sentence(feats, tags)\n",
    "        return forward_score - gold_score\n",
    "\n",
    "    def forward(self, sentence):  # dont confuse this with _forward_alg above.\n",
    "        # Get the emission scores from the BiLSTM\n",
    "        lstm_feats = self._get_lstm_features(sentence)\n",
    "\n",
    "        # Find the best path, given the features.\n",
    "        score, tag_seq = self._viterbi_decode(lstm_feats)\n",
    "        return score, tag_seq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iM3CgGFptOaN"
   },
   "source": [
    "# 6. Data Preparation For Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ybUfoH4fun7j"
   },
   "outputs": [],
   "source": [
    "## make word into ix for training and testing - Lab 9\n",
    "def to_index(data, to_ix):\n",
    "    input_index_list = []\n",
    "    for sent in data:\n",
    "        input_index_list.append([to_ix[w] for w in sent])\n",
    "    return input_index_list\n",
    "\n",
    "all_sentence_index = to_index(all_sentence, word_2_ix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ydPH4ZfqvLG5"
   },
   "outputs": [],
   "source": [
    "## make labels into ix\n",
    "unique_NER = []\n",
    "for line in train_NER:\n",
    "  unique_NER.extend(line)\n",
    "unique_tag= list(set(unique_NER))\n",
    "\n",
    "START_TAG = \"<START>\"\n",
    "STOP_TAG = \"<STOP>\"\n",
    "\n",
    "tag_2_ix = {tag: ix + 2 for ix, tag in enumerate(unique_tag)}\n",
    "tag_2_ix[\"<START>\"] = 0\n",
    "tag_2_ix[\"<STOP>\"] = 1\n",
    "ix_2_tag = {ix: tag for tag,ix in tag_2_ix.items()}\n",
    "\n",
    "# transform tags into idx\n",
    "train_NER_index = to_index(train_NER, tag_2_ix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xgXGbkoZ5Gla"
   },
   "outputs": [],
   "source": [
    "# make other features into ix\n",
    "all_sentence_pos = to_index(pos, other_feature_2_ix)\n",
    "all_sentence_pt = to_index(pt, other_feature_2_ix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Array for selected model scores\n",
    "scores = np.zeros(13)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gRwdm0QDbxrt"
   },
   "source": [
    "# 7. Different Model Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "D3r0zNXG0RIk"
   },
   "source": [
    "## 7.1 Baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "36h-E9YS0W9q"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "HIDDEN_DIM = 50\n",
    "OTHER_FEATURE_DIM = 20\n",
    "NUM_LAYER = 1\n",
    "\n",
    "model = BiLSTM_CRF(len(word_2_ix), tag_2_ix, EMBEDDING_DIM, OTHER_FEATURE_DIM, HIDDEN_DIM, attetion = \"No Attention\", other_features = [], layers = NUM_LAYER)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, weight_decay=1e-4)\n",
    "\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mUr0beLG0jz6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:1, Training loss: 9812.25, time: 164.57s\n",
      "Epoch:2, Training loss: 5165.15, time: 164.08s\n",
      "Epoch:3, Training loss: 3882.39, time: 164.82s\n",
      "Epoch:4, Training loss: 3090.34, time: 163.36s\n",
      "Epoch:5, Training loss: 2531.92, time: 162.72s\n",
      "Epoch:6, Training loss: 2098.31, time: 167.82s\n",
      "Epoch:7, Training loss: 1705.86, time: 162.44s\n",
      "Epoch:8, Training loss: 1372.70, time: 165.50s\n",
      "Epoch:9, Training loss: 1132.07, time: 168.76s\n",
      "Epoch:10, Training loss: 958.66, time: 166.57s\n",
      "Epoch:11, Training loss: 761.55, time: 165.81s\n",
      "Epoch:12, Training loss: 653.88, time: 167.91s\n",
      "Epoch:13, Training loss: 522.50, time: 164.12s\n",
      "Epoch:14, Training loss: 454.56, time: 162.45s\n",
      "Epoch:15, Training loss: 376.39, time: 166.19s\n",
      "Epoch:16, Training loss: 347.63, time: 167.54s\n",
      "Epoch:17, Training loss: 295.13, time: 169.70s\n",
      "Epoch:18, Training loss: 284.19, time: 159.39s\n",
      "Epoch:19, Training loss: 254.77, time: 133.62s\n",
      "Epoch:20, Training loss: 203.32, time: 156.37s\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Each epoch will take about 1-2 minutes\"\"\"\n",
    "\n",
    "import datetime\n",
    "\n",
    "for epoch in range(20):  \n",
    "    time1 = datetime.datetime.now()\n",
    "    train_loss = 0\n",
    "\n",
    "    model.train()\n",
    "    for i, idxs in enumerate(all_sentence_index[:3000]):\n",
    "        \n",
    "        tags_index = train_NER_index[i]\n",
    "        # Step 1. Remember that Pytorch accumulates gradients.\n",
    "        # We need to clear them out before each instance\n",
    "        model.zero_grad()\n",
    "\n",
    "        # Step 2. Get our inputs ready for the network, that is,\n",
    "        # turn them into Tensors of word indices.\n",
    "        sentence_in = torch.tensor(idxs, dtype=torch.long).to(device)\n",
    "        targets = torch.tensor(tags_index, dtype=torch.long).to(device)\n",
    "\n",
    "        # Step new. Add other features as input\n",
    "        other_feature = {}\n",
    "        other_feature[\"pos\"] = torch.tensor(all_sentence_pos[i], dtype=torch.long).to(device)\n",
    "        other_feature[\"pt\"] = torch.tensor(all_sentence_pt[i], dtype=torch.long).to(device)\n",
    "\n",
    "        # Step 3. Run our forward pass.\n",
    "        loss = model.neg_log_likelihood(sentence_in, targets, other_feature)\n",
    "\n",
    "        # Step 4. Compute the loss, gradients, and update the parameters by\n",
    "        # calling optimizer.step()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss+=loss.item()\n",
    "\n",
    "    time2 = datetime.datetime.now()\n",
    "\n",
    "    # print(\"Epoch:%d, Training loss: %.2f, train acc: %.4f, val loss: %.2f, val acc: %.4f, time: %.2fs\" %(epoch+1, train_loss,train_acc, val_loss, val_acc, (time2-time1).total_seconds()))\n",
    "    print(\"Epoch:%d, Training loss: %.2f, time: %.2fs\" %(epoch+1, train_loss, (time2-time1).total_seconds()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 275
    },
    "colab_type": "code",
    "id": "Qar5231G2vPp",
    "outputId": "8ff96bd7-1c7f-4020-d384-72d4fca969a8"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/erasure/lib/python3.6/site-packages/torch/serialization.py:360: UserWarning: Couldn't retrieve source code for container of type BiLSTM_CRF. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9658549497088407\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           2     0.8247    0.6791    0.7449       187\n",
      "           3     0.9772    0.9303    0.9532       875\n",
      "           4     0.9749    0.9934    0.9841      5790\n",
      "           5     0.8780    0.7579    0.8136       285\n",
      "           6     0.9196    0.9284    0.9240       419\n",
      "\n",
      "    accuracy                         0.9659      7556\n",
      "   macro avg     0.9149    0.8578    0.8839      7556\n",
      "weighted avg     0.9647    0.9659    0.9648      7556\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## save model\n",
    "torch.save(model, \"baseline_model.pt\")\n",
    "\n",
    "## do the prediction - test - all_features\n",
    "test_index = all_sentence_index[3700:]\n",
    "\n",
    "model.eval()\n",
    "ground_truth = []\n",
    "predicted = []\n",
    "for i in range(len(test_index)):\n",
    "  other_feature = {}\n",
    "  other_feature[\"pos\"] = torch.tensor(all_sentence_pos[i+3700], dtype=torch.long).to(device)\n",
    "  other_feature[\"pt\"] = torch.tensor(all_sentence_pt[i+3700], dtype=torch.long).to(device)\n",
    "  input = torch.tensor(test_index[i],dtype=torch.long).to(device)\n",
    "  features = model._get_lstm_features(input, other_feature)\n",
    "  score, tag_seq = model._viterbi_decode(features)\n",
    "  predicted.extend(tag_seq)\n",
    "  #ground_truth.extend(output_index[i])\n",
    "\n",
    "# output the format for submit\n",
    "import csv\n",
    "with open('baseline_model_result.csv', 'w+', newline='') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(['Id', 'Predicted'])\n",
    "    for i, y in enumerate(predicted):\n",
    "        writer.writerow([i, ix_2_tag[y]])\n",
    "\n",
    "## print f1 score for val\n",
    "y_true = []\n",
    "count = 0\n",
    "for tags in train_NER_index[3000:]:\n",
    "    y_true.extend(tags)\n",
    "\n",
    "\n",
    "val_index = all_sentence_index[3000:3700]\n",
    "model.eval()\n",
    "predicted_val = []\n",
    "for i in range(len(val_index)):\n",
    "  other_feature = {}\n",
    "  other_feature[\"pos\"] = torch.tensor(all_sentence_pos[i+3000], dtype=torch.long).to(device)\n",
    "  # print(other_feature[\"pos\"].shape)\n",
    "  other_feature[\"pt\"] = torch.tensor(all_sentence_pt[i+3000], dtype=torch.long).to(device)\n",
    "  input = torch.tensor(val_index[i],dtype=torch.long).to(device)\n",
    "  features = model._get_lstm_features(input, other_feature)\n",
    "  score, tag_seq = model._viterbi_decode(features)\n",
    "  predicted_val.extend(tag_seq)\n",
    "\n",
    "# Record all the model F1 scores\n",
    "scores[0] = f1_score(y_true,predicted_val,average='micro')\n",
    "print(scores[0])\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_true, predicted_val, digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LyxNTnN3J-fd"
   },
   "source": [
    "## 7.2 two layers + dot product attention + word embedding + pt + pos features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vbppw_YvAVAJ"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "HIDDEN_DIM = 50\n",
    "OTHER_FEATURE_DIM = 20\n",
    "NUM_LAYER = 2\n",
    "ATTENTION = [\"Dot Product\", \"Scale Dot Product\"]\n",
    "\n",
    "# remove string from list to remove features\n",
    "ADDITION_FEATURE = [\"pt\",\"pos\"]\n",
    "\n",
    "model = BiLSTM_CRF(len(word_2_ix), tag_2_ix, EMBEDDING_DIM, OTHER_FEATURE_DIM, HIDDEN_DIM, attetion = ATTENTION[0], other_features = [\"pt\",\"pos\"], layers = NUM_LAYER).to(device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, weight_decay=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153
    },
    "colab_type": "code",
    "id": "KE3JGvHqB1z3",
    "outputId": "b2faa443-2942-48ee-d9e5-3881eef19b9a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:1, Training loss: 12324.24, time: 148.56s\n",
      "Epoch:2, Training loss: 5796.74, time: 137.74s\n",
      "Epoch:3, Training loss: 4271.71, time: 137.88s\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-142-141a9083fcd2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;31m# Step 3. Run our forward pass.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mneg_log_likelihood\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother_feature\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0;31m# Step 4. Compute the loss, gradients, and update the parameters by\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-134-b92cf11065a3>\u001b[0m in \u001b[0;36mneg_log_likelihood\u001b[0;34m(self, sentence, tags, other_feature)\u001b[0m\n\u001b[1;32m    179\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mneg_log_likelihood\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother_feature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m         \u001b[0mfeats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_lstm_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother_feature\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m         \u001b[0mforward_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_alg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeats\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    182\u001b[0m         \u001b[0mgold_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_score_sentence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mforward_score\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mgold_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-134-b92cf11065a3>\u001b[0m in \u001b[0;36m_forward_alg\u001b[0;34m(self, feats)\u001b[0m\n\u001b[1;32m     76\u001b[0m                 \u001b[0;31m# The forward variable for this tag is log-sum-exp of all the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m                 \u001b[0;31m# scores.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m                 \u001b[0malphas_t\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_sum_exp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_tag_var\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m             \u001b[0mforward_var\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malphas_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0mterminal_var\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mforward_var\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransitions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtag_to_ix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mSTOP_TAG\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-133-203239306e95>\u001b[0m in \u001b[0;36mlog_sum_exp\u001b[0;34m(vec)\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mmax_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvec\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mmax_score_broadcast\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax_score\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mmax_score\u001b[0m \u001b[0;34m+\u001b[0m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvec\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mmax_score_broadcast\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\"\"\"Each epoch will take about 1-2 minutes\"\"\"\n",
    "\n",
    "import datetime\n",
    "\n",
    "for epoch in range(20):  \n",
    "    time1 = datetime.datetime.now()\n",
    "    train_loss = 0\n",
    "\n",
    "    model.train()\n",
    "    for i, idxs in enumerate(all_sentence_index[:3000]):\n",
    "        \n",
    "        tags_index = train_NER_index[i]\n",
    "        # Step 1. Remember that Pytorch accumulates gradients.\n",
    "        # We need to clear them out before each instance\n",
    "        model.zero_grad()\n",
    "\n",
    "        # Step 2. Get our inputs ready for the network, that is,\n",
    "        # turn them into Tensors of word indices.\n",
    "        sentence_in = torch.tensor(idxs, dtype=torch.long).to(device)\n",
    "        targets = torch.tensor(tags_index, dtype=torch.long).to(device)\n",
    "\n",
    "        # Step new. Add other features as input\n",
    "        other_feature = {}\n",
    "        other_feature[\"pos\"] = torch.tensor(all_sentence_pos[i], dtype=torch.long).to(device)\n",
    "        other_feature[\"pt\"] = torch.tensor(all_sentence_pt[i], dtype=torch.long).to(device)\n",
    "\n",
    "        # Step 3. Run our forward pass.\n",
    "        loss = model.neg_log_likelihood(sentence_in, targets, other_feature)\n",
    "\n",
    "        # Step 4. Compute the loss, gradients, and update the parameters by\n",
    "        # calling optimizer.step()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss+=loss.item()\n",
    "\n",
    "    time2 = datetime.datetime.now()\n",
    "\n",
    "    # print(\"Epoch:%d, Training loss: %.2f, train acc: %.4f, val loss: %.2f, val acc: %.4f, time: %.2fs\" %(epoch+1, train_loss,train_acc, val_loss, val_acc, (time2-time1).total_seconds()))\n",
    "    print(\"Epoch:%d, Training loss: %.2f, time: %.2fs\" %(epoch+1, train_loss, (time2-time1).total_seconds()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 275
    },
    "colab_type": "code",
    "id": "bRWuWmYU3tIN",
    "outputId": "02cda7b6-77a6-460a-87ea-0fa3f0ba21f0"
   },
   "outputs": [],
   "source": [
    "## save model\n",
    "torch.save(model, \"pt_pos_word_2_layer_dot_prodcut.pt\")\n",
    "\n",
    "## do the prediction - test - all_features\n",
    "test_index = all_sentence_index[3700:]\n",
    "\n",
    "model.eval()\n",
    "ground_truth = []\n",
    "predicted = []\n",
    "for i in range(len(test_index)):\n",
    "  other_feature = {}\n",
    "  other_feature[\"pos\"] = torch.tensor(all_sentence_pos[i+3700], dtype=torch.long).to(device)\n",
    "  other_feature[\"pt\"] = torch.tensor(all_sentence_pt[i+3700], dtype=torch.long).to(device)\n",
    "  input = torch.tensor(test_index[i],dtype=torch.long).to(device)\n",
    "  features = model._get_lstm_features(input, other_feature)\n",
    "  score, tag_seq = model._viterbi_decode(features)\n",
    "  predicted.extend(tag_seq)\n",
    "  #ground_truth.extend(output_index[i])\n",
    "\n",
    "# output the format for submit\n",
    "import csv\n",
    "with open('pt_pos_word_2_layer_dot_prodcut_result', 'w+', newline='') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(['Id', 'Predicted'])\n",
    "    for i, y in enumerate(predicted):\n",
    "        writer.writerow([i, ix_2_tag[y]])\n",
    "\n",
    "## print f1 socre for val\n",
    "y_true = []\n",
    "count = 0\n",
    "for tags in train_NER_index[3000:]:\n",
    "    y_true.extend(tags)\n",
    "\n",
    "\n",
    "val_index = all_sentence_index[3000:3700]\n",
    "model.eval()\n",
    "predicted_val = []\n",
    "for i in range(len(val_index)):\n",
    "  other_feature = {}\n",
    "  other_feature[\"pos\"] = torch.tensor(all_sentence_pos[i+3000], dtype=torch.long).to(device)\n",
    "  # print(other_feature[\"pos\"].shape)\n",
    "  other_feature[\"pt\"] = torch.tensor(all_sentence_pt[i+3000], dtype=torch.long).to(device)\n",
    "  input = torch.tensor(val_index[i],dtype=torch.long).to(device)\n",
    "  features = model._get_lstm_features(input, other_feature)\n",
    "  score, tag_seq = model._viterbi_decode(features)\n",
    "  predicted_val.extend(tag_seq)\n",
    "\n",
    "# Record all the model F1 scores\n",
    "scores[1] = f1_score(y_true,predicted_val,average='micro')\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_true, predicted_val, digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vLUUhH6NuQ9G"
   },
   "source": [
    "## 7.3 one layer + dot product + only word embedding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TsRpSt0epfg5"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "HIDDEN_DIM = 50\n",
    "OTHER_FEATURE_DIM = 20\n",
    "NUM_LAYER = 1\n",
    "ATTENTION = [\"Dot Product\", \"Scale Dot Product\"]\n",
    "\n",
    "\n",
    "model = BiLSTM_CRF(len(word_2_ix), tag_2_ix, EMBEDDING_DIM, OTHER_FEATURE_DIM, HIDDEN_DIM, \n",
    "                   attetion = ATTENTION[0], other_features = [], layers = NUM_LAYER).to(device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, weight_decay=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 357
    },
    "colab_type": "code",
    "id": "xuFtfW5w481Q",
    "outputId": "a7e64ee2-e14a-40ab-9aac-3220591990cb"
   },
   "outputs": [],
   "source": [
    "\"\"\"Each epoch will take about 1-2 minutes\"\"\"\n",
    "\n",
    "import datetime\n",
    "\n",
    "for epoch in range(20):  \n",
    "    time1 = datetime.datetime.now()\n",
    "    train_loss = 0\n",
    "\n",
    "    model.train()\n",
    "    for i, idxs in enumerate(all_sentence_index[:3000]):\n",
    "        \n",
    "        tags_index = train_NER_index[i]\n",
    "        # Step 1. Remember that Pytorch accumulates gradients.\n",
    "        # We need to clear them out before each instance\n",
    "        model.zero_grad()\n",
    "\n",
    "        # Step 2. Get our inputs ready for the network, that is,\n",
    "        # turn them into Tensors of word indices.\n",
    "        sentence_in = torch.tensor(idxs, dtype=torch.long).to(device)\n",
    "        targets = torch.tensor(tags_index, dtype=torch.long).to(device)\n",
    "\n",
    "        # Step new. Add other features as input\n",
    "        other_feature = {}\n",
    "        other_feature[\"pos\"] = torch.tensor(all_sentence_pos[i], dtype=torch.long).to(device)\n",
    "        other_feature[\"pt\"] = torch.tensor(all_sentence_pt[i], dtype=torch.long).to(device)\n",
    "\n",
    "        # Step 3. Run our forward pass.\n",
    "        loss = model.neg_log_likelihood(sentence_in, targets, other_feature)\n",
    "\n",
    "        # Step 4. Compute the loss, gradients, and update the parameters by\n",
    "        # calling optimizer.step()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss+=loss.item()\n",
    "\n",
    "    time2 = datetime.datetime.now()\n",
    "\n",
    "    # print(\"Epoch:%d, Training loss: %.2f, train acc: %.4f, val loss: %.2f, val acc: %.4f, time: %.2fs\" %(epoch+1, train_loss,train_acc, val_loss, val_acc, (time2-time1).total_seconds()))\n",
    "    print(\"Epoch:%d, Training loss: %.2f, time: %.2fs\" %(epoch+1, train_loss, (time2-time1).total_seconds()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 275
    },
    "colab_type": "code",
    "id": "LwKhyUTa5Eu7",
    "outputId": "84600832-c296-4758-ae09-5323e6a5a14d"
   },
   "outputs": [],
   "source": [
    "## save model\n",
    "torch.save(model, \"word_1_layer_dot_prodcut.pt\")\n",
    "\n",
    "## do the prediction - test - all_features\n",
    "test_index = all_sentence_index[3700:]\n",
    "\n",
    "model.eval()\n",
    "ground_truth = []\n",
    "predicted = []\n",
    "for i in range(len(test_index)):\n",
    "  other_feature = {}\n",
    "  other_feature[\"pos\"] = torch.tensor(all_sentence_pos[i+3700], dtype=torch.long).to(device)\n",
    "  other_feature[\"pt\"] = torch.tensor(all_sentence_pt[i+3700], dtype=torch.long).to(device)\n",
    "  input = torch.tensor(test_index[i],dtype=torch.long).to(device)\n",
    "  features = model._get_lstm_features(input, other_feature)\n",
    "  score, tag_seq = model._viterbi_decode(features)\n",
    "  predicted.extend(tag_seq)\n",
    "  #ground_truth.extend(output_index[i])\n",
    "\n",
    "# output the format for submit\n",
    "import csv\n",
    "with open('word_1_layer_dot_prodcut_result.csv', 'w+', newline='') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(['Id', 'Predicted'])\n",
    "    for i, y in enumerate(predicted):\n",
    "        writer.writerow([i, ix_2_tag[y]])\n",
    "\n",
    "## print f1 socre for val\n",
    "y_true = []\n",
    "count = 0\n",
    "for tags in train_NER_index[3000:]:\n",
    "    y_true.extend(tags)\n",
    "\n",
    "\n",
    "val_index = all_sentence_index[3000:3700]\n",
    "model.eval()\n",
    "predicted_val = []\n",
    "for i in range(len(val_index)):\n",
    "  other_feature = {}\n",
    "  other_feature[\"pos\"] = torch.tensor(all_sentence_pos[i+3000], dtype=torch.long).to(device)  \n",
    "  # print(other_feature[\"pos\"].shape)\n",
    "  other_feature[\"pt\"] = torch.tensor(all_sentence_pt[i+3000], dtype=torch.long).to(device)\n",
    "  input = torch.tensor(val_index[i],dtype=torch.long).to(device)\n",
    "  features = model._get_lstm_features(input, other_feature)\n",
    "  score, tag_seq = model._viterbi_decode(features)\n",
    "  predicted_val.extend(tag_seq)\n",
    "\n",
    "# Record all the model F1 scores\n",
    "scores[2] = f1_score(y_true,predicted_val,average='micro')\n",
    "    \n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_true, predicted_val, digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2GDEwIEC4Ite"
   },
   "source": [
    "## 7.4 one layer + scale dot product + only word embedding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sif4j83X4MU7"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "HIDDEN_DIM = 50\n",
    "OTHER_FEATURE_DIM = 20\n",
    "NUM_LAYER = 1\n",
    "ATTENTION = [\"Dot Product\", \"Scale Dot Product\"]\n",
    "\n",
    "\n",
    "model = BiLSTM_CRF(len(word_2_ix), tag_2_ix, EMBEDDING_DIM, OTHER_FEATURE_DIM, HIDDEN_DIM, \n",
    "                   attetion = ATTENTION[1], other_features = [], layers = NUM_LAYER).to(device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, weight_decay=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 357
    },
    "colab_type": "code",
    "id": "y9uC3KkC49iz",
    "outputId": "e2711d81-7a0d-4b60-caa0-fe3a014a3ae4"
   },
   "outputs": [],
   "source": [
    "\"\"\"Each epoch will take about 1-2 minutes\"\"\"\n",
    "\n",
    "import datetime\n",
    "\n",
    "for epoch in range(20):  \n",
    "    time1 = datetime.datetime.now()\n",
    "    train_loss = 0\n",
    "\n",
    "    model.train()\n",
    "    for i, idxs in enumerate(all_sentence_index[:3000]):\n",
    "        \n",
    "        tags_index = train_NER_index[i]\n",
    "        # Step 1. Remember that Pytorch accumulates gradients.\n",
    "        # We need to clear them out before each instance\n",
    "        model.zero_grad()\n",
    "\n",
    "        # Step 2. Get our inputs ready for the network, that is,\n",
    "        # turn them into Tensors of word indices.\n",
    "        sentence_in = torch.tensor(idxs, dtype=torch.long).to(device)\n",
    "        targets = torch.tensor(tags_index, dtype=torch.long).to(device)\n",
    "\n",
    "        # Step new. Add other features as input\n",
    "        other_feature = {}\n",
    "        other_feature[\"pos\"] = torch.tensor(all_sentence_pos[i], dtype=torch.long).to(device)\n",
    "        other_feature[\"pt\"] = torch.tensor(all_sentence_pt[i], dtype=torch.long).to(device)\n",
    "\n",
    "        # Step 3. Run our forward pass.\n",
    "        loss = model.neg_log_likelihood(sentence_in, targets, other_feature)\n",
    "\n",
    "        # Step 4. Compute the loss, gradients, and update the parameters by\n",
    "        # calling optimizer.step()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss+=loss.item()\n",
    "\n",
    "    time2 = datetime.datetime.now()\n",
    "\n",
    "    # print(\"Epoch:%d, Training loss: %.2f, train acc: %.4f, val loss: %.2f, val acc: %.4f, time: %.2fs\" %(epoch+1, train_loss,train_acc, val_loss, val_acc, (time2-time1).total_seconds()))\n",
    "    print(\"Epoch:%d, Training loss: %.2f, time: %.2fs\" %(epoch+1, train_loss, (time2-time1).total_seconds()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 275
    },
    "colab_type": "code",
    "id": "aAHzUv8Q5Flw",
    "outputId": "5d4920be-571f-4b0e-e78a-398df0d6bc44"
   },
   "outputs": [],
   "source": [
    "## save model\n",
    "torch.save(model, \"word_1_layer_scale_dot_prodcut.pt\")\n",
    "\n",
    "## do the prediction - test - all_features\n",
    "test_index = all_sentence_index[3700:]\n",
    "\n",
    "model.eval()\n",
    "ground_truth = []\n",
    "predicted = []\n",
    "for i in range(len(test_index)):\n",
    "  other_feature = {}\n",
    "  other_feature[\"pos\"] = torch.tensor(all_sentence_pos[i+3700], dtype=torch.long).to(device)\n",
    "  other_feature[\"pt\"] = torch.tensor(all_sentence_pt[i+3700], dtype=torch.long).to(device)\n",
    "  input = torch.tensor(test_index[i],dtype=torch.long).to(device)\n",
    "  features = model._get_lstm_features(input, other_feature)\n",
    "  score, tag_seq = model._viterbi_decode(features)\n",
    "  predicted.extend(tag_seq)\n",
    "  #ground_truth.extend(output_index[i])\n",
    "\n",
    "# output the format for submit\n",
    "import csv\n",
    "with open('word_1_layer_scale_dot_prodcut_result.csv', 'w+', newline='') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(['Id', 'Predicted'])\n",
    "    for i, y in enumerate(predicted):\n",
    "        writer.writerow([i, ix_2_tag[y]])\n",
    "\n",
    "## print f1 socre for val\n",
    "y_true = []\n",
    "count = 0\n",
    "for tags in train_NER_index[3000:]:\n",
    "    y_true.extend(tags)\n",
    "\n",
    "\n",
    "val_index = all_sentence_index[3000:3700]\n",
    "model.eval()\n",
    "predicted_val = []\n",
    "for i in range(len(val_index)):\n",
    "  other_feature = {}\n",
    "  other_feature[\"pos\"] = torch.tensor(all_sentence_pos[i+3000], dtype=torch.long).to(device)\n",
    "  # print(other_feature[\"pos\"].shape)\n",
    "  other_feature[\"pt\"] = torch.tensor(all_sentence_pt[i+3000], dtype=torch.long).to(device)\n",
    "  input = torch.tensor(val_index[i],dtype=torch.long).to(device)\n",
    "  features = model._get_lstm_features(input, other_feature)\n",
    "  score, tag_seq = model._viterbi_decode(features)\n",
    "  predicted_val.extend(tag_seq)\n",
    "\n",
    "# Record all the model F1 scores\n",
    "scores[3] = f1_score(y_true,predicted_val,average='micro')\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_true, predicted_val, digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aXGuZTqD4P7O"
   },
   "source": [
    "## 7.5 two layer + scale dot product + only word embedding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tMc_MOz64Pbh"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "HIDDEN_DIM = 50\n",
    "OTHER_FEATURE_DIM = 20\n",
    "NUM_LAYER = 2\n",
    "ATTENTION = [\"Dot Product\", \"Scale Dot Product\"]\n",
    "\n",
    "\n",
    "model = BiLSTM_CRF(len(word_2_ix), tag_2_ix, EMBEDDING_DIM, OTHER_FEATURE_DIM, HIDDEN_DIM, \n",
    "                   attetion = ATTENTION[1], other_features = [], layers = NUM_LAYER).to(device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, weight_decay=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 357
    },
    "colab_type": "code",
    "id": "U2krB8vW5oNf",
    "outputId": "0d359b46-4d9b-41c8-b651-deece757f01f"
   },
   "outputs": [],
   "source": [
    "\"\"\"Each epoch will take about 1-2 minutes\"\"\"\n",
    "\n",
    "import datetime\n",
    "\n",
    "for epoch in range(20):  \n",
    "    time1 = datetime.datetime.now()\n",
    "    train_loss = 0\n",
    "\n",
    "    model.train()\n",
    "    for i, idxs in enumerate(all_sentence_index[:3000]):\n",
    "        \n",
    "        tags_index = train_NER_index[i]\n",
    "        # Step 1. Remember that Pytorch accumulates gradients.\n",
    "        # We need to clear them out before each instance\n",
    "        model.zero_grad()\n",
    "\n",
    "        # Step 2. Get our inputs ready for the network, that is,\n",
    "        # turn them into Tensors of word indices.\n",
    "        sentence_in = torch.tensor(idxs, dtype=torch.long).to(device)\n",
    "        targets = torch.tensor(tags_index, dtype=torch.long).to(device)\n",
    "\n",
    "        # Step new. Add other features as input\n",
    "        other_feature = {}\n",
    "        other_feature[\"pos\"] = torch.tensor(all_sentence_pos[i], dtype=torch.long).to(device)\n",
    "        other_feature[\"pt\"] = torch.tensor(all_sentence_pt[i], dtype=torch.long).to(device)\n",
    "\n",
    "        # Step 3. Run our forward pass.\n",
    "        loss = model.neg_log_likelihood(sentence_in, targets, other_feature)\n",
    "\n",
    "        # Step 4. Compute the loss, gradients, and update the parameters by\n",
    "        # calling optimizer.step()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss+=loss.item()\n",
    "\n",
    "    time2 = datetime.datetime.now()\n",
    "\n",
    "    # print(\"Epoch:%d, Training loss: %.2f, train acc: %.4f, val loss: %.2f, val acc: %.4f, time: %.2fs\" %(epoch+1, train_loss,train_acc, val_loss, val_acc, (time2-time1).total_seconds()))\n",
    "    print(\"Epoch:%d, Training loss: %.2f, time: %.2fs\" %(epoch+1, train_loss, (time2-time1).total_seconds()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 275
    },
    "colab_type": "code",
    "id": "oBKT5d8w5GPH",
    "outputId": "eedc61ef-3b73-4cfa-f684-988ca460b423"
   },
   "outputs": [],
   "source": [
    "## save model\n",
    "torch.save(model, \"word_2_layer_scale_dot_prodcut.pt\")\n",
    "\n",
    "## do the prediction - test - all_features\n",
    "test_index = all_sentence_index[3700:]\n",
    "\n",
    "model.eval()\n",
    "ground_truth = []\n",
    "predicted = []\n",
    "for i in range(len(test_index)):\n",
    "  other_feature = {}\n",
    "  other_feature[\"pos\"] = torch.tensor(all_sentence_pos[i+3700], dtype=torch.long).to(device)\n",
    "  other_feature[\"pt\"] = torch.tensor(all_sentence_pt[i+3700], dtype=torch.long).to(device)\n",
    "  input = torch.tensor(test_index[i],dtype=torch.long).to(device)\n",
    "  features = model._get_lstm_features(input, other_feature)\n",
    "  score, tag_seq = model._viterbi_decode(features)\n",
    "  predicted.extend(tag_seq)\n",
    "  #ground_truth.extend(output_index[i])\n",
    "\n",
    "# output the format for submit\n",
    "import csv\n",
    "with open('word_2_layer_scale_dot_prodcut_result.csv', 'w+', newline='') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(['Id', 'Predicted'])\n",
    "    for i, y in enumerate(predicted):\n",
    "        writer.writerow([i, ix_2_tag[y]])\n",
    "\n",
    "## print f1 socre for val\n",
    "y_true = []\n",
    "count = 0\n",
    "for tags in train_NER_index[3000:]:\n",
    "    y_true.extend(tags)\n",
    "\n",
    "\n",
    "val_index = all_sentence_index[3000:3700]\n",
    "model.eval()\n",
    "predicted_val = []\n",
    "for i in range(len(val_index)):\n",
    "  other_feature = {}\n",
    "  other_feature[\"pos\"] = torch.tensor(all_sentence_pos[i+3000], dtype=torch.long).to(device)\n",
    "  # print(other_feature[\"pos\"].shape)\n",
    "  other_feature[\"pt\"] = torch.tensor(all_sentence_pt[i+3000], dtype=torch.long).to(device)\n",
    "  input = torch.tensor(val_index[i],dtype=torch.long).to(device)\n",
    "  features = model._get_lstm_features(input, other_feature)\n",
    "  score, tag_seq = model._viterbi_decode(features)\n",
    "  predicted_val.extend(tag_seq)\n",
    "\n",
    "# Record all the model F1 scores\n",
    "scores[4] = f1_score(y_true,predicted_val,average='micro')\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_true, predicted_val, digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "V6J4Mwnp4pcd"
   },
   "source": [
    "## 7.6 two layers + scale dot product + word embedding + pos feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yuxcoP_u4Uxd"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "HIDDEN_DIM = 50\n",
    "OTHER_FEATURE_DIM = 20\n",
    "NUM_LAYER = 2\n",
    "ATTENTION = [\"Dot Product\", \"Scale Dot Product\"]\n",
    "\n",
    "\n",
    "model = BiLSTM_CRF(len(word_2_ix), tag_2_ix, EMBEDDING_DIM, OTHER_FEATURE_DIM, HIDDEN_DIM, \n",
    "                   attetion = ATTENTION[1], other_features = [\"pos\"], layers = NUM_LAYER).to(device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, weight_decay=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 357
    },
    "colab_type": "code",
    "id": "nZXiWRw94-t-",
    "outputId": "b7fc058a-8ecc-4b77-88ca-e1ba1ec10c42"
   },
   "outputs": [],
   "source": [
    "\"\"\"Each epoch will take about 1-2 minutes\"\"\"\n",
    "\n",
    "import datetime\n",
    "\n",
    "for epoch in range(20):  \n",
    "    time1 = datetime.datetime.now()\n",
    "    train_loss = 0\n",
    "\n",
    "    model.train()\n",
    "    for i, idxs in enumerate(all_sentence_index[:3000]):\n",
    "        \n",
    "        tags_index = train_NER_index[i]\n",
    "        # Step 1. Remember that Pytorch accumulates gradients.\n",
    "        # We need to clear them out before each instance\n",
    "        model.zero_grad()\n",
    "\n",
    "        # Step 2. Get our inputs ready for the network, that is,\n",
    "        # turn them into Tensors of word indices.\n",
    "        sentence_in = torch.tensor(idxs, dtype=torch.long).to(device)\n",
    "        targets = torch.tensor(tags_index, dtype=torch.long).to(device)\n",
    "\n",
    "        # Step new. Add other features as input\n",
    "        other_feature = {}\n",
    "        other_feature[\"pos\"] = torch.tensor(all_sentence_pos[i], dtype=torch.long).to(device)\n",
    "        other_feature[\"pt\"] = torch.tensor(all_sentence_pt[i], dtype=torch.long).to(device)\n",
    "\n",
    "        # Step 3. Run our forward pass.\n",
    "        loss = model.neg_log_likelihood(sentence_in, targets, other_feature)\n",
    "\n",
    "        # Step 4. Compute the loss, gradients, and update the parameters by\n",
    "        # calling optimizer.step()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss+=loss.item()\n",
    "\n",
    "    time2 = datetime.datetime.now()\n",
    "\n",
    "    # print(\"Epoch:%d, Training loss: %.2f, train acc: %.4f, val loss: %.2f, val acc: %.4f, time: %.2fs\" %(epoch+1, train_loss,train_acc, val_loss, val_acc, (time2-time1).total_seconds()))\n",
    "    print(\"Epoch:%d, Training loss: %.2f, time: %.2fs\" %(epoch+1, train_loss, (time2-time1).total_seconds()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 275
    },
    "colab_type": "code",
    "id": "w4zsDwgd5HtB",
    "outputId": "3e7119bc-284d-4b7f-b0dd-9ef1189bf358"
   },
   "outputs": [],
   "source": [
    "## save model\n",
    "torch.save(model, \"pos_word_2_layer_scale_dot_prodcut.pt\")\n",
    "\n",
    "## do the prediction - test - all_features\n",
    "test_index = all_sentence_index[3700:]\n",
    "\n",
    "model.eval()\n",
    "ground_truth = []\n",
    "predicted = []\n",
    "for i in range(len(test_index)):\n",
    "  other_feature = {}\n",
    "  other_feature[\"pos\"] = torch.tensor(all_sentence_pos[i+3700], dtype=torch.long).to(device)\n",
    "  other_feature[\"pt\"] = torch.tensor(all_sentence_pt[i+3700], dtype=torch.long).to(device)\n",
    "  input = torch.tensor(test_index[i],dtype=torch.long).to(device)\n",
    "  features = model._get_lstm_features(input, other_feature)\n",
    "  score, tag_seq = model._viterbi_decode(features)\n",
    "  predicted.extend(tag_seq)\n",
    "  #ground_truth.extend(output_index[i])\n",
    "\n",
    "# output the format for submit\n",
    "import csv\n",
    "with open('pos_word_2_layer_scale_dot_prodcut_result.csv', 'w+', newline='') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(['Id', 'Predicted'])\n",
    "    for i, y in enumerate(predicted):\n",
    "        writer.writerow([i, ix_2_tag[y]])\n",
    "\n",
    "## print f1 socre for val\n",
    "y_true = []\n",
    "count = 0\n",
    "for tags in train_NER_index[3000:]:\n",
    "    y_true.extend(tags)\n",
    "\n",
    "\n",
    "val_index = all_sentence_index[3000:3700]\n",
    "model.eval()\n",
    "predicted_val = []\n",
    "for i in range(len(val_index)):\n",
    "  other_feature = {}\n",
    "  other_feature[\"pos\"] = torch.tensor(all_sentence_pos[i+3000], dtype=torch.long).to(device)\n",
    "  # print(other_feature[\"pos\"].shape)\n",
    "  other_feature[\"pt\"] = torch.tensor(all_sentence_pt[i+3000], dtype=torch.long).to(device)\n",
    "  input = torch.tensor(val_index[i],dtype=torch.long).to(device)\n",
    "  features = model._get_lstm_features(input, other_feature)\n",
    "  score, tag_seq = model._viterbi_decode(features)\n",
    "  predicted_val.extend(tag_seq)\n",
    "\n",
    "# Record all the model F1 scores\n",
    "scores[5] = f1_score(y_true,predicted_val,average='micro')\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_true, predicted_val, digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xXRuHmzW4z0R"
   },
   "source": [
    "## 7.7 two layers + scale dot product + word embedding + pt + pos features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "e1q3NV8J4yRH"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "HIDDEN_DIM = 50\n",
    "OTHER_FEATURE_DIM = 20\n",
    "NUM_LAYER = 2\n",
    "ATTENTION = [\"Dot Product\", \"Scale Dot Product\"]\n",
    "\n",
    "\n",
    "model = BiLSTM_CRF(len(word_2_ix), tag_2_ix, EMBEDDING_DIM, OTHER_FEATURE_DIM, HIDDEN_DIM, \n",
    "                   attetion = ATTENTION[1], other_features = [\"pos\",\"pt\"], layers = NUM_LAYER).to(device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, weight_decay=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 357
    },
    "colab_type": "code",
    "id": "nH3FsgI14_Pv",
    "outputId": "b5d1eecf-e312-45a5-e3a8-daf96af24957"
   },
   "outputs": [],
   "source": [
    "\"\"\"Each epoch will take about 1-2 minutes\"\"\"\n",
    "\n",
    "import datetime\n",
    "\n",
    "for epoch in range(20):  \n",
    "    time1 = datetime.datetime.now()\n",
    "    train_loss = 0\n",
    "\n",
    "    model.train()\n",
    "    for i, idxs in enumerate(all_sentence_index[:3000]):\n",
    "        \n",
    "        tags_index = train_NER_index[i]\n",
    "        # Step 1. Remember that Pytorch accumulates gradients.\n",
    "        # We need to clear them out before each instance\n",
    "        model.zero_grad()\n",
    "\n",
    "        # Step 2. Get our inputs ready for the network, that is,\n",
    "        # turn them into Tensors of word indices.\n",
    "        sentence_in = torch.tensor(idxs, dtype=torch.long).to(device)\n",
    "        targets = torch.tensor(tags_index, dtype=torch.long).to(device)\n",
    "\n",
    "        # Step new. Add other features as input\n",
    "        other_feature = {}\n",
    "        other_feature[\"pos\"] = torch.tensor(all_sentence_pos[i], dtype=torch.long).to(device)\n",
    "        other_feature[\"pt\"] = torch.tensor(all_sentence_pt[i], dtype=torch.long).to(device)\n",
    "\n",
    "        # Step 3. Run our forward pass.\n",
    "        loss = model.neg_log_likelihood(sentence_in, targets, other_feature)\n",
    "\n",
    "        # Step 4. Compute the loss, gradients, and update the parameters by\n",
    "        # calling optimizer.step()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss+=loss.item()\n",
    "\n",
    "    time2 = datetime.datetime.now()\n",
    "\n",
    "    # print(\"Epoch:%d, Training loss: %.2f, train acc: %.4f, val loss: %.2f, val acc: %.4f, time: %.2fs\" %(epoch+1, train_loss,train_acc, val_loss, val_acc, (time2-time1).total_seconds()))\n",
    "    print(\"Epoch:%d, Training loss: %.2f, time: %.2fs\" %(epoch+1, train_loss, (time2-time1).total_seconds()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 275
    },
    "colab_type": "code",
    "id": "BcVFuCeA45Ya",
    "outputId": "2e3db212-a47b-40a5-b9d7-070521e92e04"
   },
   "outputs": [],
   "source": [
    "## save model\n",
    "torch.save(model, \"pt_pos_word_2_layer_scale_dot_prodcut.pt\")\n",
    "\n",
    "## do the prediction - test - all_features\n",
    "test_index = all_sentence_index[3700:]\n",
    "\n",
    "model.eval()\n",
    "ground_truth = []\n",
    "predicted = []\n",
    "for i in range(len(test_index)):\n",
    "  other_feature = {}\n",
    "  other_feature[\"pos\"] = torch.tensor(all_sentence_pos[i+3700], dtype=torch.long).to(device)\n",
    "  other_feature[\"pt\"] = torch.tensor(all_sentence_pt[i+3700], dtype=torch.long).to(device)\n",
    "  input = torch.tensor(test_index[i],dtype=torch.long).to(device)\n",
    "  features = model._get_lstm_features(input, other_feature)\n",
    "  score, tag_seq = model._viterbi_decode(features)\n",
    "  predicted.extend(tag_seq)\n",
    "  #ground_truth.extend(output_index[i])\n",
    "\n",
    "# output the format for submit\n",
    "import csv\n",
    "with open('pt_pos_word_2_layer_scale_dot_prodcut_result.csv', 'w+', newline='') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(['Id', 'Predicted'])\n",
    "    for i, y in enumerate(predicted):\n",
    "        writer.writerow([i, ix_2_tag[y]])\n",
    "\n",
    "## print f1 socre for val\n",
    "y_true = []\n",
    "count = 0\n",
    "for tags in train_NER_index[3000:]:\n",
    "    y_true.extend(tags)\n",
    "\n",
    "\n",
    "val_index = all_sentence_index[3000:3700]\n",
    "model.eval()\n",
    "predicted_val = []\n",
    "for i in range(len(val_index)):\n",
    "  other_feature = {}\n",
    "  other_feature[\"pos\"] = torch.tensor(all_sentence_pos[i+3000], dtype=torch.long).to(device)\n",
    "  # print(other_feature[\"pos\"].shape)\n",
    "  other_feature[\"pt\"] = torch.tensor(all_sentence_pt[i+3000], dtype=torch.long).to(device)\n",
    "  input = torch.tensor(val_index[i],dtype=torch.long).to(device)\n",
    "  features = model._get_lstm_features(input, other_feature)\n",
    "  score, tag_seq = model._viterbi_decode(features)\n",
    "  predicted_val.extend(tag_seq)\n",
    "\n",
    "# Record all the model F1 scores\n",
    "scores[6] = f1_score(y_true,predicted_val,average='micro')\n",
    "    \n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_true, predicted_val, digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FOkVj9HckDai"
   },
   "source": [
    "## 7.8 two layers + dot production attention + word embedding + pos feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Go7vxseRnGo0"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "HIDDEN_DIM = 50\n",
    "OTHER_FEATURE_DIM = 20\n",
    "NUM_LAYER = 2\n",
    "ATTENTION = [\"Dot Product\", \"Scale Dot Product\"]\n",
    "\n",
    "\n",
    "model = BiLSTM_CRF(len(word_2_ix), tag_2_ix, EMBEDDING_DIM, OTHER_FEATURE_DIM, HIDDEN_DIM, \n",
    "                   attetion = ATTENTION[0], other_features = [\"pos\"], layers = NUM_LAYER).to(device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, weight_decay=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "id": "8F34FOAEoAPl",
    "outputId": "36b487f6-9c43-45c9-fe88-13ece575640e"
   },
   "outputs": [],
   "source": [
    "\"\"\"Each epoch will take about 1-2 minutes\"\"\"\n",
    "\n",
    "import datetime\n",
    "\n",
    "for epoch in range(20):  \n",
    "    time1 = datetime.datetime.now()\n",
    "    train_loss = 0\n",
    "\n",
    "    model.train()\n",
    "    for i, idxs in enumerate(all_sentence_index[:3000]):\n",
    "        \n",
    "        tags_index = train_NER_index[i]\n",
    "        # Step 1. Remember that Pytorch accumulates gradients.\n",
    "        # We need to clear them out before each instance\n",
    "        model.zero_grad()\n",
    "\n",
    "        # Step 2. Get our inputs ready for the network, that is,\n",
    "        # turn them into Tensors of word indices.\n",
    "        sentence_in = torch.tensor(idxs, dtype=torch.long).to(device)\n",
    "        targets = torch.tensor(tags_index, dtype=torch.long).to(device)\n",
    "\n",
    "        # Step new. Add other features as input\n",
    "        other_feature = {}\n",
    "        other_feature[\"pos\"] = torch.tensor(all_sentence_pos[i], dtype=torch.long).to(device)\n",
    "        other_feature[\"pt\"] = torch.tensor(all_sentence_pt[i], dtype=torch.long).to(device)\n",
    "\n",
    "        # Step 3. Run our forward pass.\n",
    "        loss = model.neg_log_likelihood(sentence_in, targets, other_feature)\n",
    "\n",
    "        # Step 4. Compute the loss, gradients, and update the parameters by\n",
    "        # calling optimizer.step()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss+=loss.item()\n",
    "\n",
    "    time2 = datetime.datetime.now()\n",
    "\n",
    "    # print(\"Epoch:%d, Training loss: %.2f, train acc: %.4f, val loss: %.2f, val acc: %.4f, time: %.2fs\" %(epoch+1, train_loss,train_acc, val_loss, val_acc, (time2-time1).total_seconds()))\n",
    "    print(\"Epoch:%d, Training loss: %.2f, time: %.2fs\" %(epoch+1, train_loss, (time2-time1).total_seconds()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hY43IGOOoVb7"
   },
   "outputs": [],
   "source": [
    "## save model\n",
    "torch.save(model, \"pos_word_2_layer_dot_prodcut.pt\")\n",
    "\n",
    "## do the prediction - test - all_features\n",
    "test_index = all_sentence_index[3700:]\n",
    "\n",
    "model.eval()\n",
    "ground_truth = []\n",
    "predicted = []\n",
    "for i in range(len(test_index)):\n",
    "  other_feature = {}\n",
    "  other_feature[\"pos\"] = torch.tensor(all_sentence_pos[i+3700], dtype=torch.long).to(device)\n",
    "  other_feature[\"pt\"] = torch.tensor(all_sentence_pt[i+3700], dtype=torch.long).to(device)\n",
    "  input = torch.tensor(test_index[i],dtype=torch.long).to(device)\n",
    "  features = model._get_lstm_features(input, other_feature)\n",
    "  score, tag_seq = model._viterbi_decode(features)\n",
    "  predicted.extend(tag_seq)\n",
    "  #ground_truth.extend(output_index[i])\n",
    "\n",
    "# output the format for submit\n",
    "import csv\n",
    "with open('pos_word_2_layer_dot_prodcut.csv', 'w+', newline='') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(['Id', 'Predicted'])\n",
    "    for i, y in enumerate(predicted):\n",
    "        writer.writerow([i, ix_2_tag[y]])\n",
    "\n",
    "## print f1 socre for val\n",
    "y_true = []\n",
    "count = 0\n",
    "for tags in train_NER_index[3000:]:\n",
    "    y_true.extend(tags)\n",
    "\n",
    "\n",
    "val_index = all_sentence_index[3000:3700]\n",
    "model.eval()\n",
    "predicted_val = []\n",
    "for i in range(len(val_index)):\n",
    "  other_feature = {}\n",
    "  other_feature[\"pos\"] = torch.tensor(all_sentence_pos[i+3000], dtype=torch.long).to(device)\n",
    "  # print(other_feature[\"pos\"].shape)\n",
    "  other_feature[\"pt\"] = torch.tensor(all_sentence_pt[i+3000], dtype=torch.long).to(device)\n",
    "  input = torch.tensor(val_index[i],dtype=torch.long).to(device)\n",
    "  features = model._get_lstm_features(input, other_feature)\n",
    "  score, tag_seq = model._viterbi_decode(features)\n",
    "  predicted_val.extend(tag_seq)\n",
    "\n",
    "# Record all the model F1 scores\n",
    "scores[7] = f1_score(y_true,predicted_val,average='micro')\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_true, predicted_val, digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nVw9Wgk1l_6z"
   },
   "source": [
    "## 7.9 two layers + dot production attention + only word embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ef5fqD7TniRw"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "HIDDEN_DIM = 50\n",
    "OTHER_FEATURE_DIM = 20\n",
    "NUM_LAYER = 2\n",
    "ATTENTION = [\"Dot Product\", \"Scale Dot Product\"]\n",
    "\n",
    "\n",
    "model = BiLSTM_CRF(len(word_2_ix), tag_2_ix, EMBEDDING_DIM, OTHER_FEATURE_DIM, HIDDEN_DIM, \n",
    "                   attetion = ATTENTION[0], other_features = [], layers = NUM_LAYER).to(device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, weight_decay=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZehdENhLoCQt"
   },
   "outputs": [],
   "source": [
    "\"\"\"Each epoch will take about 1-2 minutes\"\"\"\n",
    "\n",
    "import datetime\n",
    "\n",
    "for epoch in range(20):  \n",
    "    time1 = datetime.datetime.now()\n",
    "    train_loss = 0\n",
    "\n",
    "    model.train()\n",
    "    for i, idxs in enumerate(all_sentence_index[:3000]):\n",
    "        \n",
    "        tags_index = train_NER_index[i]\n",
    "        # Step 1. Remember that Pytorch accumulates gradients.\n",
    "        # We need to clear them out before each instance\n",
    "        model.zero_grad()\n",
    "\n",
    "        # Step 2. Get our inputs ready for the network, that is,\n",
    "        # turn them into Tensors of word indices.\n",
    "        sentence_in = torch.tensor(idxs, dtype=torch.long).to(device)\n",
    "        targets = torch.tensor(tags_index, dtype=torch.long).to(device)\n",
    "\n",
    "        # Step new. Add other features as input\n",
    "        other_feature = {}\n",
    "        other_feature[\"pos\"] = torch.tensor(all_sentence_pos[i], dtype=torch.long).to(device)\n",
    "        other_feature[\"pt\"] = torch.tensor(all_sentence_pt[i], dtype=torch.long).to(device)\n",
    "\n",
    "        # Step 3. Run our forward pass.\n",
    "        loss = model.neg_log_likelihood(sentence_in, targets, other_feature)\n",
    "\n",
    "        # Step 4. Compute the loss, gradients, and update the parameters by\n",
    "        # calling optimizer.step()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss+=loss.item()\n",
    "\n",
    "    time2 = datetime.datetime.now()\n",
    "\n",
    "    # print(\"Epoch:%d, Training loss: %.2f, train acc: %.4f, val loss: %.2f, val acc: %.4f, time: %.2fs\" %(epoch+1, train_loss,train_acc, val_loss, val_acc, (time2-time1).total_seconds()))\n",
    "    print(\"Epoch:%d, Training loss: %.2f, time: %.2fs\" %(epoch+1, train_loss, (time2-time1).total_seconds()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7AVp0ooPoXO1"
   },
   "outputs": [],
   "source": [
    "## save model\n",
    "torch.save(model, \"word_2_layer_dot_prodcut.pt\")\n",
    "\n",
    "## do the prediction - test - all_features\n",
    "test_index = all_sentence_index[3700:]\n",
    "\n",
    "model.eval()\n",
    "ground_truth = []\n",
    "predicted = []\n",
    "for i in range(len(test_index)):\n",
    "  other_feature = {}\n",
    "  other_feature[\"pos\"] = torch.tensor(all_sentence_pos[i+3700], dtype=torch.long).to(device)\n",
    "  other_feature[\"pt\"] = torch.tensor(all_sentence_pt[i+3700], dtype=torch.long).to(device)\n",
    "  input = torch.tensor(test_index[i],dtype=torch.long).to(device)\n",
    "  features = model._get_lstm_features(input, other_feature)\n",
    "  score, tag_seq = model._viterbi_decode(features)\n",
    "  predicted.extend(tag_seq)\n",
    "  #ground_truth.extend(output_index[i])\n",
    "\n",
    "# output the format for submit\n",
    "import csv\n",
    "with open('word_2_layer_dot_prodcut.csv', 'w+', newline='') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(['Id', 'Predicted'])\n",
    "    for i, y in enumerate(predicted):\n",
    "        writer.writerow([i, ix_2_tag[y]])\n",
    "\n",
    "## print f1 socre for val\n",
    "y_true = []\n",
    "count = 0\n",
    "for tags in train_NER_index[3000:]:\n",
    "    y_true.extend(tags)\n",
    "\n",
    "\n",
    "val_index = all_sentence_index[3000:3700]\n",
    "model.eval()\n",
    "predicted_val = []\n",
    "for i in range(len(val_index)):\n",
    "  other_feature = {}\n",
    "  other_feature[\"pos\"] = torch.tensor(all_sentence_pos[i+3000], dtype=torch.long).to(device)\n",
    "  # print(other_feature[\"pos\"].shape)\n",
    "  other_feature[\"pt\"] = torch.tensor(all_sentence_pt[i+3000], dtype=torch.long).to(device)\n",
    "  input = torch.tensor(val_index[i],dtype=torch.long).to(device)\n",
    "  features = model._get_lstm_features(input, other_feature)\n",
    "  score, tag_seq = model._viterbi_decode(features)\n",
    "  predicted_val.extend(tag_seq)\n",
    "\n",
    "# Record all the model F1 scores\n",
    "scores[8] = f1_score(y_true,predicted_val,average='micro')\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_true, predicted_val, digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0UaACleKmN8h"
   },
   "source": [
    "## 7.10 one layer + dot production attention + word embedding + pt + pos features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "C5bPh4JgnqTa"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "HIDDEN_DIM = 50\n",
    "OTHER_FEATURE_DIM = 20\n",
    "NUM_LAYER = 1\n",
    "ATTENTION = [\"Dot Product\", \"Scale Dot Product\"]\n",
    "\n",
    "\n",
    "model = BiLSTM_CRF(len(word_2_ix), tag_2_ix, EMBEDDING_DIM, OTHER_FEATURE_DIM, HIDDEN_DIM, \n",
    "                   attetion = ATTENTION[0], other_features = [\"pos\",\"pt\"], layers = NUM_LAYER).to(device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, weight_decay=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ta0oQ1cnoDQd"
   },
   "outputs": [],
   "source": [
    "\"\"\"Each epoch will take about 1-2 minutes\"\"\"\n",
    "\n",
    "import datetime\n",
    "\n",
    "for epoch in range(20):  \n",
    "    time1 = datetime.datetime.now()\n",
    "    train_loss = 0\n",
    "\n",
    "    model.train()\n",
    "    for i, idxs in enumerate(all_sentence_index[:3000]):\n",
    "        \n",
    "        tags_index = train_NER_index[i]\n",
    "        # Step 1. Remember that Pytorch accumulates gradients.\n",
    "        # We need to clear them out before each instance\n",
    "        model.zero_grad()\n",
    "\n",
    "        # Step 2. Get our inputs ready for the network, that is,\n",
    "        # turn them into Tensors of word indices.\n",
    "        sentence_in = torch.tensor(idxs, dtype=torch.long).to(device)\n",
    "        targets = torch.tensor(tags_index, dtype=torch.long).to(device)\n",
    "\n",
    "        # Step new. Add other features as input\n",
    "        other_feature = {}\n",
    "        other_feature[\"pos\"] = torch.tensor(all_sentence_pos[i], dtype=torch.long).to(device)\n",
    "        other_feature[\"pt\"] = torch.tensor(all_sentence_pt[i], dtype=torch.long).to(device)\n",
    "\n",
    "        # Step 3. Run our forward pass.\n",
    "        loss = model.neg_log_likelihood(sentence_in, targets, other_feature)\n",
    "\n",
    "        # Step 4. Compute the loss, gradients, and update the parameters by\n",
    "        # calling optimizer.step()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss+=loss.item()\n",
    "\n",
    "    time2 = datetime.datetime.now()\n",
    "\n",
    "    # print(\"Epoch:%d, Training loss: %.2f, train acc: %.4f, val loss: %.2f, val acc: %.4f, time: %.2fs\" %(epoch+1, train_loss,train_acc, val_loss, val_acc, (time2-time1).total_seconds()))\n",
    "    print(\"Epoch:%d, Training loss: %.2f, time: %.2fs\" %(epoch+1, train_loss, (time2-time1).total_seconds()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hq--aPxHoZcz"
   },
   "outputs": [],
   "source": [
    "## save model\n",
    "torch.save(model, \"pt_pos_word_1_layer_dot_prodcut.pt\")\n",
    "\n",
    "## do the prediction - test - all_features\n",
    "test_index = all_sentence_index[3700:]\n",
    "\n",
    "model.eval()\n",
    "ground_truth = []\n",
    "predicted = []\n",
    "for i in range(len(test_index)):\n",
    "  other_feature = {}\n",
    "  other_feature[\"pos\"] = torch.tensor(all_sentence_pos[i+3700], dtype=torch.long).to(device)\n",
    "  other_feature[\"pt\"] = torch.tensor(all_sentence_pt[i+3700], dtype=torch.long).to(device)\n",
    "  input = torch.tensor(test_index[i],dtype=torch.long).to(device)\n",
    "  features = model._get_lstm_features(input, other_feature)\n",
    "  score, tag_seq = model._viterbi_decode(features)\n",
    "  predicted.extend(tag_seq)\n",
    "  #ground_truth.extend(output_index[i])\n",
    "\n",
    "# output the format for submit\n",
    "import csv\n",
    "with open('pt_pos_word_1_layer_dot_prodcut.csv', 'w+', newline='') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(['Id', 'Predicted'])\n",
    "    for i, y in enumerate(predicted):\n",
    "        writer.writerow([i, ix_2_tag[y]])\n",
    "\n",
    "## print f1 socre for val\n",
    "y_true = []\n",
    "count = 0\n",
    "for tags in train_NER_index[3000:]:\n",
    "    y_true.extend(tags)\n",
    "\n",
    "\n",
    "val_index = all_sentence_index[3000:3700]\n",
    "model.eval()\n",
    "predicted_val = []\n",
    "for i in range(len(val_index)):\n",
    "  other_feature = {}\n",
    "  other_feature[\"pos\"] = torch.tensor(all_sentence_pos[i+3000], dtype=torch.long).to(device)\n",
    "  # print(other_feature[\"pos\"].shape)\n",
    "  other_feature[\"pt\"] = torch.tensor(all_sentence_pt[i+3000], dtype=torch.long).to(device)\n",
    "  input = torch.tensor(val_index[i],dtype=torch.long).to(device)\n",
    "  features = model._get_lstm_features(input, other_feature)\n",
    "  score, tag_seq = model._viterbi_decode(features)\n",
    "  predicted_val.extend(tag_seq)\n",
    "\n",
    "# Record all the model F1 scores\n",
    "scores[9] = f1_score(y_true,predicted_val,average='micro')\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_true, predicted_val, digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OnvFAVWKmtGH"
   },
   "source": [
    "## 7.11 one layer + dot production attention + word embedding + pos feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_jGNq_cXntth"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "HIDDEN_DIM = 50\n",
    "OTHER_FEATURE_DIM = 20\n",
    "NUM_LAYER = 1\n",
    "ATTENTION = [\"Dot Product\", \"Scale Dot Product\"]\n",
    "\n",
    "\n",
    "model = BiLSTM_CRF(len(word_2_ix), tag_2_ix, EMBEDDING_DIM, OTHER_FEATURE_DIM, HIDDEN_DIM, \n",
    "                   attetion = ATTENTION[0], other_features = [\"pos\"], layers = NUM_LAYER).to(device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, weight_decay=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "R6TNw6N9oEHF"
   },
   "outputs": [],
   "source": [
    "\"\"\"Each epoch will take about 1-2 minutes\"\"\"\n",
    "\n",
    "import datetime\n",
    "\n",
    "for epoch in range(20):  \n",
    "    time1 = datetime.datetime.now()\n",
    "    train_loss = 0\n",
    "\n",
    "    model.train()\n",
    "    for i, idxs in enumerate(all_sentence_index[:3000]):\n",
    "        \n",
    "        tags_index = train_NER_index[i]\n",
    "        # Step 1. Remember that Pytorch accumulates gradients.\n",
    "        # We need to clear them out before each instance\n",
    "        model.zero_grad()\n",
    "\n",
    "        # Step 2. Get our inputs ready for the network, that is,\n",
    "        # turn them into Tensors of word indices.\n",
    "        sentence_in = torch.tensor(idxs, dtype=torch.long).to(device)\n",
    "        targets = torch.tensor(tags_index, dtype=torch.long).to(device)\n",
    "\n",
    "        # Step new. Add other features as input\n",
    "        other_feature = {}\n",
    "        other_feature[\"pos\"] = torch.tensor(all_sentence_pos[i], dtype=torch.long).to(device)\n",
    "        other_feature[\"pt\"] = torch.tensor(all_sentence_pt[i], dtype=torch.long).to(device)\n",
    "\n",
    "        # Step 3. Run our forward pass.\n",
    "        loss = model.neg_log_likelihood(sentence_in, targets, other_feature)\n",
    "\n",
    "        # Step 4. Compute the loss, gradients, and update the parameters by\n",
    "        # calling optimizer.step()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss+=loss.item()\n",
    "\n",
    "    time2 = datetime.datetime.now()\n",
    "\n",
    "    # print(\"Epoch:%d, Training loss: %.2f, train acc: %.4f, val loss: %.2f, val acc: %.4f, time: %.2fs\" %(epoch+1, train_loss,train_acc, val_loss, val_acc, (time2-time1).total_seconds()))\n",
    "    print(\"Epoch:%d, Training loss: %.2f, time: %.2fs\" %(epoch+1, train_loss, (time2-time1).total_seconds()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RklFw9YUoamG"
   },
   "outputs": [],
   "source": [
    "## save model\n",
    "torch.save(model, \"pos_word_1_layer_dot_prodcut.pt\")\n",
    "\n",
    "## do the prediction - test - all_features\n",
    "test_index = all_sentence_index[3700:]\n",
    "\n",
    "model.eval()\n",
    "ground_truth = []\n",
    "predicted = []\n",
    "for i in range(len(test_index)):\n",
    "  other_feature = {}\n",
    "  other_feature[\"pos\"] = torch.tensor(all_sentence_pos[i+3700], dtype=torch.long).to(device)\n",
    "  other_feature[\"pt\"] = torch.tensor(all_sentence_pt[i+3700], dtype=torch.long).to(device)\n",
    "  input = torch.tensor(test_index[i],dtype=torch.long).to(device)\n",
    "  features = model._get_lstm_features(input, other_feature)\n",
    "  score, tag_seq = model._viterbi_decode(features)\n",
    "  predicted.extend(tag_seq)\n",
    "  #ground_truth.extend(output_index[i])\n",
    "\n",
    "# output the format for submit\n",
    "import csv\n",
    "with open('pos_word_1_layer_dot_prodcut.csv', 'w+', newline='') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(['Id', 'Predicted'])\n",
    "    for i, y in enumerate(predicted):\n",
    "        writer.writerow([i, ix_2_tag[y]])\n",
    "\n",
    "## print f1 socre for val\n",
    "y_true = []\n",
    "count = 0\n",
    "for tags in train_NER_index[3000:]:\n",
    "    y_true.extend(tags)\n",
    "\n",
    "\n",
    "val_index = all_sentence_index[3000:3700]\n",
    "model.eval()\n",
    "predicted_val = []\n",
    "for i in range(len(val_index)):\n",
    "  other_feature = {}\n",
    "  other_feature[\"pos\"] = torch.tensor(all_sentence_pos[i+3000], dtype=torch.long).to(device)\n",
    "  # print(other_feature[\"pos\"].shape)\n",
    "  other_feature[\"pt\"] = torch.tensor(all_sentence_pt[i+3000], dtype=torch.long).to(device)\n",
    "  input = torch.tensor(val_index[i],dtype=torch.long).to(device)\n",
    "  features = model._get_lstm_features(input, other_feature)\n",
    "  score, tag_seq = model._viterbi_decode(features)\n",
    "  predicted_val.extend(tag_seq)\n",
    "\n",
    "# Record all the model F1 scores\n",
    "scores[10] = f1_score(y_true,predicted_val,average='micro')\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_true, predicted_val, digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KzHEVDUpmwTE"
   },
   "source": [
    "## 7.12 one layer + scale dot production attention + word embedding + pt + pos features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wPGZkvLSnyvj"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "HIDDEN_DIM = 50\n",
    "OTHER_FEATURE_DIM = 20\n",
    "NUM_LAYER = 1\n",
    "ATTENTION = [\"Dot Product\", \"Scale Dot Product\"]\n",
    "\n",
    "\n",
    "model = BiLSTM_CRF(len(word_2_ix), tag_2_ix, EMBEDDING_DIM, OTHER_FEATURE_DIM, HIDDEN_DIM, \n",
    "                   attetion = ATTENTION[1], other_features = [\"pos\",\"pt\"], layers = NUM_LAYER).to(device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, weight_decay=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mRfCxrCyoE5m"
   },
   "outputs": [],
   "source": [
    "\"\"\"Each epoch will take about 1-2 minutes\"\"\"\n",
    "\n",
    "import datetime\n",
    "\n",
    "for epoch in range(20):  \n",
    "    time1 = datetime.datetime.now()\n",
    "    train_loss = 0\n",
    "\n",
    "    model.train()\n",
    "    for i, idxs in enumerate(all_sentence_index[:3000]):\n",
    "        \n",
    "        tags_index = train_NER_index[i]\n",
    "        # Step 1. Remember that Pytorch accumulates gradients.\n",
    "        # We need to clear them out before each instance\n",
    "        model.zero_grad()\n",
    "\n",
    "        # Step 2. Get our inputs ready for the network, that is,\n",
    "        # turn them into Tensors of word indices.\n",
    "        sentence_in = torch.tensor(idxs, dtype=torch.long).to(device)\n",
    "        targets = torch.tensor(tags_index, dtype=torch.long).to(device)\n",
    "\n",
    "        # Step new. Add other features as input\n",
    "        other_feature = {}\n",
    "        other_feature[\"pos\"] = torch.tensor(all_sentence_pos[i], dtype=torch.long).to(device)\n",
    "        other_feature[\"pt\"] = torch.tensor(all_sentence_pt[i], dtype=torch.long).to(device)\n",
    "\n",
    "        # Step 3. Run our forward pass.\n",
    "        loss = model.neg_log_likelihood(sentence_in, targets, other_feature)\n",
    "\n",
    "        # Step 4. Compute the loss, gradients, and update the parameters by\n",
    "        # calling optimizer.step()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss+=loss.item()\n",
    "\n",
    "    time2 = datetime.datetime.now()\n",
    "\n",
    "    # print(\"Epoch:%d, Training loss: %.2f, train acc: %.4f, val loss: %.2f, val acc: %.4f, time: %.2fs\" %(epoch+1, train_loss,train_acc, val_loss, val_acc, (time2-time1).total_seconds()))\n",
    "    print(\"Epoch:%d, Training loss: %.2f, time: %.2fs\" %(epoch+1, train_loss, (time2-time1).total_seconds()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Tq1EMs-2obxX"
   },
   "outputs": [],
   "source": [
    "## save model\n",
    "torch.save(model, \"pt_pos_word_1_layer_scale_dot_prodcut.pt\")\n",
    "\n",
    "## do the prediction - test - all_features\n",
    "test_index = all_sentence_index[3700:]\n",
    "\n",
    "model.eval()\n",
    "ground_truth = []\n",
    "predicted = []\n",
    "for i in range(len(test_index)):\n",
    "  other_feature = {}\n",
    "  other_feature[\"pos\"] = torch.tensor(all_sentence_pos[i+3700], dtype=torch.long).to(device)\n",
    "  other_feature[\"pt\"] = torch.tensor(all_sentence_pt[i+3700], dtype=torch.long).to(device)\n",
    "  input = torch.tensor(test_index[i],dtype=torch.long).to(device)\n",
    "  features = model._get_lstm_features(input, other_feature)\n",
    "  score, tag_seq = model._viterbi_decode(features)\n",
    "  predicted.extend(tag_seq)\n",
    "  #ground_truth.extend(output_index[i])\n",
    "\n",
    "# output the format for submit\n",
    "import csv\n",
    "with open('pt_pos_word_1_layer_scale_dot_prodcut.csv', 'w+', newline='') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(['Id', 'Predicted'])\n",
    "    for i, y in enumerate(predicted):\n",
    "        writer.writerow([i, ix_2_tag[y]])\n",
    "\n",
    "## print f1 socre for val\n",
    "y_true = []\n",
    "count = 0\n",
    "for tags in train_NER_index[3000:]:\n",
    "    y_true.extend(tags)\n",
    "\n",
    "\n",
    "val_index = all_sentence_index[3000:3700]\n",
    "model.eval()\n",
    "predicted_val = []\n",
    "for i in range(len(val_index)):\n",
    "  other_feature = {}\n",
    "  other_feature[\"pos\"] = torch.tensor(all_sentence_pos[i+3000], dtype=torch.long).to(device)\n",
    "  # print(other_feature[\"pos\"].shape)\n",
    "  other_feature[\"pt\"] = torch.tensor(all_sentence_pt[i+3000], dtype=torch.long).to(device)\n",
    "  input = torch.tensor(val_index[i],dtype=torch.long).to(device)\n",
    "  features = model._get_lstm_features(input, other_feature)\n",
    "  score, tag_seq = model._viterbi_decode(features)\n",
    "  predicted_val.extend(tag_seq)\n",
    "\n",
    "# Record all the model F1 scores\n",
    "scores[11] = f1_score(y_true,predicted_val,average='micro')\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_true, predicted_val, digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "v-JgydUfm62z"
   },
   "source": [
    "## 7.13 one layer + scale dot production attention + word embedding + pos feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XJwXCGacn10z"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "HIDDEN_DIM = 50\n",
    "OTHER_FEATURE_DIM = 20\n",
    "NUM_LAYER = 1\n",
    "ATTENTION = [\"Dot Product\", \"Scale Dot Product\"]\n",
    "\n",
    "\n",
    "model = BiLSTM_CRF(len(word_2_ix), tag_2_ix, EMBEDDING_DIM, OTHER_FEATURE_DIM, HIDDEN_DIM, \n",
    "                   attetion = ATTENTION[1], other_features = [\"pos\"], layers = NUM_LAYER).to(device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, weight_decay=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "epwS-lfeoFpO"
   },
   "outputs": [],
   "source": [
    "\"\"\"Each epoch will take about 1-2 minutes\"\"\"\n",
    "\n",
    "import datetime\n",
    "\n",
    "for epoch in range(20):  \n",
    "    time1 = datetime.datetime.now()\n",
    "    train_loss = 0\n",
    "\n",
    "    model.train()\n",
    "    for i, idxs in enumerate(all_sentence_index[:3000]):\n",
    "        \n",
    "        tags_index = train_NER_index[i]\n",
    "        # Step 1. Remember that Pytorch accumulates gradients.\n",
    "        # We need to clear them out before each instance\n",
    "        model.zero_grad()\n",
    "\n",
    "        # Step 2. Get our inputs ready for the network, that is,\n",
    "        # turn them into Tensors of word indices.\n",
    "        sentence_in = torch.tensor(idxs, dtype=torch.long).to(device)\n",
    "        targets = torch.tensor(tags_index, dtype=torch.long).to(device)\n",
    "\n",
    "        # Step new. Add other features as input\n",
    "        other_feature = {}\n",
    "        other_feature[\"pos\"] = torch.tensor(all_sentence_pos[i], dtype=torch.long).to(device)\n",
    "        other_feature[\"pt\"] = torch.tensor(all_sentence_pt[i], dtype=torch.long).to(device)\n",
    "\n",
    "        # Step 3. Run our forward pass.\n",
    "        loss = model.neg_log_likelihood(sentence_in, targets, other_feature)\n",
    "\n",
    "        # Step 4. Compute the loss, gradients, and update the parameters by\n",
    "        # calling optimizer.step()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss+=loss.item()\n",
    "\n",
    "    time2 = datetime.datetime.now()\n",
    "\n",
    "    # print(\"Epoch:%d, Training loss: %.2f, train acc: %.4f, val loss: %.2f, val acc: %.4f, time: %.2fs\" %(epoch+1, train_loss,train_acc, val_loss, val_acc, (time2-time1).total_seconds()))\n",
    "    print(\"Epoch:%d, Training loss: %.2f, time: %.2fs\" %(epoch+1, train_loss, (time2-time1).total_seconds()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "x97nTfIUoc58"
   },
   "outputs": [],
   "source": [
    "## save model\n",
    "torch.save(model, \"pos_word_1_layer_scale_dot_prodcut.pt\")\n",
    "\n",
    "## do the prediction - test - all_features\n",
    "test_index = all_sentence_index[3700:]\n",
    "\n",
    "model.eval()\n",
    "ground_truth = []\n",
    "predicted = []\n",
    "for i in range(len(test_index)):\n",
    "  other_feature = {}\n",
    "  other_feature[\"pos\"] = torch.tensor(all_sentence_pos[i+3700], dtype=torch.long).to(device)\n",
    "  other_feature[\"pt\"] = torch.tensor(all_sentence_pt[i+3700], dtype=torch.long).to(device)\n",
    "  input = torch.tensor(test_index[i],dtype=torch.long).to(device)\n",
    "  features = model._get_lstm_features(input, other_feature)\n",
    "  score, tag_seq = model._viterbi_decode(features)\n",
    "  predicted.extend(tag_seq)\n",
    "  #ground_truth.extend(output_index[i])\n",
    "\n",
    "# output the format for submit\n",
    "import csv\n",
    "with open('pos_word_1_layer_scale_dot_prodcut.csv', 'w+', newline='') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(['Id', 'Predicted'])\n",
    "    for i, y in enumerate(predicted):\n",
    "        writer.writerow([i, ix_2_tag[y]])\n",
    "\n",
    "## print f1 socre for val\n",
    "y_true = []\n",
    "count = 0\n",
    "for tags in train_NER_index[3000:]:\n",
    "    y_true.extend(tags)\n",
    "\n",
    "\n",
    "val_index = all_sentence_index[3000:3700]\n",
    "model.eval()\n",
    "predicted_val = []\n",
    "for i in range(len(val_index)):\n",
    "  other_feature = {}\n",
    "  other_feature[\"pos\"] = torch.tensor(all_sentence_pos[i+3000], dtype=torch.long).to(device)\n",
    "  # print(other_feature[\"pos\"].shape)\n",
    "  other_feature[\"pt\"] = torch.tensor(all_sentence_pt[i+3000], dtype=torch.long).to(device)\n",
    "  input = torch.tensor(val_index[i],dtype=torch.long).to(device)\n",
    "  features = model._get_lstm_features(input, other_feature)\n",
    "  score, tag_seq = model._viterbi_decode(features)\n",
    "  predicted_val.extend(tag_seq)\n",
    "\n",
    "# Record all the model F1 scores\n",
    "scores[12] = f1_score(y_true,predicted_val,average='micro')\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_true, predicted_val, digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.1 Summarise model scores from selected models in Section 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best performing model from select set\n",
    "baseline_score = np.round(scores[0],4)\n",
    "model_scores = np.round(scores[1:],4)\n",
    "best_params = np.where(model_scores==np.amax(model_scores))\n",
    "\n",
    "# Print table summarising scores compared to other models\n",
    "from prettytable import PrettyTable\n",
    "t = PrettyTable(['Models', 'F1'])\n",
    "t.add_row(['Baseline', baseline_score])\n",
    "t.add_row(['Best other model', float(model_scores[best_params])])\n",
    "print(t)\n",
    "\n",
    "t = PrettyTable()\n",
    "t.field_names = ['Selective Search - Models', 'F1']\n",
    "t.align[\"Selective Search - Models\"] = \"l\"\n",
    "t.align[\"F1\"] = \"l\"\n",
    "\n",
    "t.add_row(['7.1 Baseline', baseline_score])\n",
    "t.add_row(['7.2 two layers + dot product attention + word embedding + pt + pos features', float(model_scores[0])])\n",
    "t.add_row(['7.3 one layer + dot product + only word embedding', float(model_scores[1])])\n",
    "t.add_row(['7.4 one layer + scale dot product + only word embedding ', float(model_scores[2])])\n",
    "t.add_row(['7.5 two layers + scale dot product + only word embedding ', float(model_scores[3])])\n",
    "t.add_row(['7.6 two layers + scale dot product + word embedding + pos feature', float(model_scores[4])])\n",
    "t.add_row(['7.7 two layers + scale dot product + word embedding + pt + pos features', float(model_scores[5])])\n",
    "t.add_row(['7.8 two layers + dot production attention + word embedding + pos feature', float(model_scores[6])])\n",
    "t.add_row(['7.9 two layers + dot production attention + only word embedding', float(model_scores[7])])\n",
    "t.add_row(['7.10 one layer + dot production attention + word embedding + pt + pos features', float(model_scores[8])])\n",
    "t.add_row(['7.11 one layer + dot production attention + word embedding + pos feature', float(model_scores[9])])\n",
    "t.add_row(['7.12 one layer + scale dot production attention + word embedding + pt + pos features', float(model_scores[10])])\n",
    "t.add_row(['7.13 one layer + scale dot production attention + word embedding + pos feature', float(model_scores[11])])\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.2 Full ablation study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/erasure/lib/python3.6/site-packages/torch/serialization.py:360: UserWarning: Couldn't retrieve source code for container of type BiLSTM_CRF. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 000: 0.9675754367390154\n",
      "Model 001: 0.9626786659608259\n",
      "Model 010: 0.9647961884595024\n",
      "Model 011: 0.9661196400211752\n",
      "Model 100: 0.9643991529910005\n",
      "Model 101: 0.964134462678666\n",
      "Model 110: 0.963208046585495\n",
      "Model 111: 0.9596347273689783\n",
      "Model 200: 0.9651932239280042\n",
      "Model 201: 0.965060878771837\n",
      "Model 210: 0.9642668078348332\n",
      "Model 211: 0.9628110111169931\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "import datetime\n",
    "import csv\n",
    "\n",
    "epochs = 20\n",
    "HIDDEN_DIM = 50\n",
    "OTHER_FEATURE_DIM = 20\n",
    "\n",
    "# Test different embeddings\n",
    "feature_flags_list = [[],[\"pos\"],[\"pt\"],[\"pos\",\"pt\"]] # 0. word embed flag 1. pos_tag flag 2. parse tree flag 3. all\n",
    "# Test different number of layers\n",
    "lstm_layers_list = [1, 2]\n",
    "# Test different attention strategies\n",
    "attention_flags = [\"No Attention\", \"Dot Product\", \"Scale Dot Product\"]\n",
    "\n",
    "# Array for model scores\n",
    "abl_scores = np.zeros((len(attention_flags),len(feature_flags_list),len(lstm_layers_list)))\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "for ai, attention in enumerate(attention_flags):\n",
    "\n",
    "    for fi, feature_flags in enumerate(feature_flags_list):\n",
    "\n",
    "        for li, lstm_layers in enumerate(lstm_layers_list):\n",
    "\n",
    "            model = BiLSTM_CRF(len(word_2_ix), tag_2_ix, EMBEDDING_DIM, OTHER_FEATURE_DIM, HIDDEN_DIM,\n",
    "                               attetion=attention, other_features=feature_flags, layers=lstm_layers).to(device)\n",
    "            optimizer = optim.SGD(model.parameters(), lr=0.01, weight_decay=1e-4)\n",
    "\n",
    "            for epoch in range(epochs):\n",
    "                time1 = datetime.datetime.now()\n",
    "                train_loss = 0\n",
    "\n",
    "                model.train()\n",
    "                for i, idxs in enumerate(all_sentence_index[:3000]):\n",
    "                    tags_index = train_NER_index[i]\n",
    "                    # Step 1. Remember that Pytorch accumulates gradients.\n",
    "                    # We need to clear them out before each instance\n",
    "                    model.zero_grad()\n",
    "\n",
    "                    # Step 2. Get our inputs ready for the network, that is,\n",
    "                    # turn them into Tensors of word indices.\n",
    "                    sentence_in = torch.tensor(idxs, dtype=torch.long).to(device)\n",
    "                    targets = torch.tensor(tags_index, dtype=torch.long).to(device)\n",
    "\n",
    "                    # Step new. Add other features as input\n",
    "                    other_feature = {}\n",
    "                    other_feature[\"pos\"] = torch.tensor(all_sentence_pos[i], dtype=torch.long).to(device)\n",
    "                    other_feature[\"pt\"] = torch.tensor(all_sentence_pt[i], dtype=torch.long).to(device)\n",
    "\n",
    "                    # Step 3. Run our forward pass.\n",
    "                    loss = model.neg_log_likelihood(sentence_in, targets, other_feature)\n",
    "\n",
    "                    # Step 4. Compute the loss, gradients, and update the parameters by\n",
    "                    # calling optimizer.step()\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "                    train_loss += loss.item()\n",
    "\n",
    "                time2 = datetime.datetime.now()\n",
    "\n",
    "                #print(\"Epoch:%d, Training loss: %.2f, time: %.2fs\" % (epoch + 1, train_loss, (time2 - time1).total_seconds()))\n",
    "                \n",
    "            ## save model\n",
    "            torch.save(model, 'model_' + str(ai)+str(fi)+str(li) +'.pt')\n",
    "\n",
    "            ## do the prediction - test - all_features\n",
    "            test_index = all_sentence_index[3700:]\n",
    "\n",
    "            model.eval()\n",
    "            ground_truth = []\n",
    "            predicted = []\n",
    "            for i in range(len(test_index)):\n",
    "                other_feature = {}\n",
    "                other_feature[\"pos\"] = torch.tensor(all_sentence_pos[i + 3700], dtype=torch.long).to(device)\n",
    "                other_feature[\"pt\"] = torch.tensor(all_sentence_pt[i + 3700], dtype=torch.long).to(device)\n",
    "                input = torch.tensor(test_index[i], dtype=torch.long).to(device)\n",
    "                features = model._get_lstm_features(input, other_feature)\n",
    "                score, tag_seq = model._viterbi_decode(features)\n",
    "                predicted.extend(tag_seq)\n",
    "                # ground_truth.extend(output_index[i])\n",
    "\n",
    "            with open('model_' + str(ai)+str(fi)+str(li) +'.csv', 'w+', newline='') as f:\n",
    "                writer = csv.writer(f)\n",
    "                writer.writerow(['Id', 'Predicted'])\n",
    "                for i, y in enumerate(predicted):\n",
    "                    writer.writerow([i, ix_2_tag[y]])\n",
    "\n",
    "            ## print f1 socre for val\n",
    "            y_true = []\n",
    "            count = 0\n",
    "            for tags in train_NER_index[3000:]:\n",
    "                y_true.extend(tags)\n",
    "\n",
    "            val_index = all_sentence_index[3000:3700]\n",
    "            model.eval()\n",
    "            predicted_val = []\n",
    "            for i in range(len(val_index)):\n",
    "                other_feature = {}\n",
    "                other_feature[\"pos\"] = torch.tensor(all_sentence_pos[i + 3000], dtype=torch.long).to(device)\n",
    "                # print(other_feature[\"pos\"].shape)\n",
    "                other_feature[\"pt\"] = torch.tensor(all_sentence_pt[i + 3000], dtype=torch.long).to(device)\n",
    "                input = torch.tensor(val_index[i], dtype=torch.long).to(device)\n",
    "                features = model._get_lstm_features(input, other_feature)\n",
    "                score, tag_seq = model._viterbi_decode(features)\n",
    "                predicted_val.extend(tag_seq)\n",
    "\n",
    "            abl_scores[ai,fi,li] = f1_score(y_true,predicted_val,average='micro')\n",
    "            print('Model ' + str(ai)+str(fi)+str(li) + ': ' + str(abl_scores[ai,fi,li]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best performing model\n",
    "best_params = np.where(abl_scores==np.amax(abl_scores))\n",
    "\n",
    "# Print table summarising scores compared to other models\n",
    "from prettytable import PrettyTable\n",
    "t = PrettyTable(['Models', 'F1'])\n",
    "t.add_row(['Baseline', abl_scores[0,0,0]])\n",
    "t.add_row(['Best other model', float(abl_scores[best_params])])\n",
    "print(t)\n",
    "\n",
    "# Print table summarising ablation studies and scores\n",
    "# Ablation Study\n",
    "t = PrettyTable(['Model', 'Attention', 'Layers', 'Embedding', 'F1'])\n",
    "t.add_row(['Baseline model', 'No Attention', '1 layer BiLSTM','Word Embedding', abl_scores[0,0,0]])\n",
    "t.add_row(['Model 1','','', '+ PoS embedding', abl_scores[0,1,0]])\n",
    "t.add_row(['Model 2','','', '+ Parse Tree embedding', abl_scores[0,2,0]])\n",
    "t.add_row(['Model 3','','', '+ ALL', abl_scores[0,3,0]])\n",
    "t.add_row(['Model 4','','2 layer BiLSTM','Word Embedding', abl_scores[0,0,1]])\n",
    "t.add_row(['Model 5','','', '+ PoS embedding', abl_scores[0,1,1]])\n",
    "t.add_row(['Model 6','','', '+ Parse Tree embedding', abl_scores[0,2,1]])\n",
    "t.add_row(['Model 7','','', '+ ALL', abl_scores[0,3,1]])\n",
    "\n",
    "t.add_row(['Model 9','Dot Product', '1 layer BiLSTM','Word Embedding', abl_scores[1,0,0]])\n",
    "t.add_row(['Model 10','','', '+ PoS embedding', abl_scores[1,1,0]])\n",
    "t.add_row(['Model 11','','', '+ Parse Tree embedding', abl_scores[1,2,0]])\n",
    "t.add_row(['Model 12','','', '+ ALL', abl_scores[1,3,0]])\n",
    "t.add_row(['Model 13','','2 layer BiLSTM','Word Embedding', abl_scores[1,0,1]])\n",
    "t.add_row(['Model 14','','', '+ PoS embedding', abl_scores[1,1,1]])\n",
    "t.add_row(['Model 15','','', '+ Parse Tree embedding', abl_scores[1,2,1]])\n",
    "t.add_row(['Model 16','','', '+ ALL', abl_scores[1,3,1]])\n",
    "\n",
    "t.add_row(['Model 17', 'Scale Dot Product', '1 layer BiLSTM','Word Embedding', abl_scores[2,0,0]])\n",
    "t.add_row(['Model 18','','', '+ PoS embedding', abl_scores[2,1,0]])\n",
    "t.add_row(['Model 19','','', '+ Parse Tree embedding', abl_scores[2,2,0]])\n",
    "t.add_row(['Model 20','','', '+ ALL', abl_scores[2,3,0]])\n",
    "t.add_row(['Model 21','','2 layer BiLSTM','Word Embedding', abl_scores[2,0,1]])\n",
    "t.add_row(['Model 22','','', '+ PoS embedding', abl_scores[2,1,1]])\n",
    "t.add_row(['Model 23','','', '+ Parse Tree embedding', abl_scores[2,2,1]])\n",
    "t.add_row(['Model 24','','', '+ ALL', abl_scores[2,3,1]])\n",
    "print(t)\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "D3r0zNXG0RIk",
    "LyxNTnN3J-fd",
    "vLUUhH6NuQ9G",
    "2GDEwIEC4Ite",
    "aXGuZTqD4P7O",
    "V6J4Mwnp4pcd",
    "xXRuHmzW4z0R"
   ],
   "name": "final_model_fixed.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
